"""
COMP5012 Final Report - Step 1: Understanding the Data
========================================================

WHAT WE'RE DOING:
    Loading and understanding the assign100.txt dataset from OR-Library.

WHY WE'RE DOING IT:
    Before implementing any algorithm, we need to understand our data structure.
    The assessment brief states we must use one of the OR-Library problems.

COURSE CONNECTION:
    - Assessment Brief: "select one of the following optimisation problems from
      the Operations Research library"
    - Lecture 2: Understanding problem formulation is the first step in any
      optimization task
    - Your Presentation: "Dataset: OR-Library assign100, Cost matrix c(i,j)
      interpreted as mission cost/risk"
"""

import numpy as np
import matplotlib.pyplot as plt  # Î“Î¹Î± visualization


# =============================================================================
# CONFIGURATION - Î‘Î›Î›Î‘ÎÎ• Î‘Î¥Î¤Î‘ Î¤Î‘ PATHS Î£Î¤ÎŸÎ Î”Î™ÎšÎŸ Î£ÎŸÎ¥ Î¦Î‘ÎšÎ•Î›ÎŸ
# =============================================================================
BASE_DIR = r'C:\Users\apzym\OneDrive\Desktop\PLYMOUTH\COMP5012'
COST_FILE = BASE_DIR + r'\assign100.txt'
COST_IMAGE = BASE_DIR + r'\cost_matrix_visualization.png'


def load_assignment_data(filepath):
    """
    Load the assignment problem data from OR-Library format.

    WHAT: Parse the assign100.txt file to extract the cost matrix.

    WHY: The cost matrix c(i,j) represents the cost of assigning drone i to area j.
         This is Objective 1 in our multi-objective problem.

    FILE FORMAT:
        - First number: problem size n (100 for assign100)
        - Following numbers: flattened nÃ—n cost matrix values

    COURSE CONNECTION:
        - Your Presentation: "Cost matrix c(i,j) interpreted as mission cost/risk"
    """
    with open(filepath, 'r') as f:
        # Read all numbers from the file
        numbers = []
        for line in f:
            numbers.extend([int(x) for x in line.split()])

    # First number is the problem size
    n = numbers[0]
    print(f"Problem size: {n} (meaning {n} drones and {n} areas)")

    # Remaining numbers form the cost matrix
    cost_values = numbers[1:]

    # Check we have enough values for an nÃ—n matrix
    expected_values = n * n
    print(f"Expected cost values: {expected_values}")
    print(f"Actual cost values found: {len(cost_values)}")

    # Reshape into nÃ—n matrix
    cost_matrix = np.array(cost_values[:expected_values]).reshape(n, n)

    return n, cost_matrix


def analyze_cost_matrix(cost_matrix):
    """
    Analyze the cost matrix to understand the problem characteristics.

    WHAT: Generate statistics about the cost matrix.

    WHY: Understanding the range and distribution of costs helps us:
         1. Design appropriate objective functions
         2. Understand what "good" vs "bad" costs look like
         3. Inform the creation of our synthetic detection probability matrix

    COURSE CONNECTION:
        - Lecture 2: "defining objective functions" requires understanding the data
    """
    print("\n" + "=" * 60)
    print("COST MATRIX ANALYSIS")
    print("=" * 60)

    print(f"\nMatrix shape: {cost_matrix.shape}")
    print(f"  Interpretation: {cost_matrix.shape[0]} drones Ã— {cost_matrix.shape[1]} areas")

    print(f"\nCost statistics:")
    print(f"  Minimum cost: {cost_matrix.min()}")
    print(f"  Maximum cost: {cost_matrix.max()}")
    print(f"  Mean cost: {cost_matrix.mean():.2f}")
    print(f"  Std deviation: {cost_matrix.std():.2f}")

    print(f"\nSample of cost matrix (first 5Ã—5 corner):")
    print(cost_matrix[:5, :5])

    # Find some example assignments
    print(f"\nExample interpretations:")
    print(f"  c(0,0) = {cost_matrix[0, 0]}: Cost of assigning drone 0 to area 0")
    print(f"  c(0,1) = {cost_matrix[0, 1]}: Cost of assigning drone 0 to area 1")
    print(f"  c(1,0) = {cost_matrix[1, 0]}: Cost of assigning drone 1 to area 0")

    # Find best and worst individual assignments
    min_idx = np.unravel_index(np.argmin(cost_matrix), cost_matrix.shape)
    max_idx = np.unravel_index(np.argmax(cost_matrix), cost_matrix.shape)

    print(f"\nBest single assignment: Drone {min_idx[0]} â†’ Area {min_idx[1]} (cost: {cost_matrix[min_idx]})")
    print(f"Worst single assignment: Drone {max_idx[0]} â†’ Area {max_idx[1]} (cost: {cost_matrix[max_idx]})")


def visualize_cost_matrix(cost_matrix, save_path):
    """
    Create and save visualization of the cost matrix.

    WHAT: Generate heatmap and histogram of cost values.

    WHY: Visual representation helps understand the data and
         creates figures for the report.

    COURSE CONNECTION:
        - Assessment rubric: "visualisations demonstrating..."
        - Lecture 2: Understanding data distribution is essential
    """
    print("\n" + "=" * 60)
    print("CREATING COST MATRIX VISUALIZATION")
    print("=" * 60)

    # Create figure with two subplots
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # ----- Left Plot: Heatmap -----
    ax1 = axes[0]
    im = ax1.imshow(cost_matrix, cmap='YlOrRd', aspect='auto')
    ax1.set_xlabel('Area Index (j)', fontsize=12)
    ax1.set_ylabel('Drone Index (i)', fontsize=12)
    ax1.set_title('Cost Matrix c(i,j)\nCost of assigning drone i to area j', fontsize=12)
    plt.colorbar(im, ax=ax1, label='Cost')

    # ----- Right Plot: Histogram -----
    ax2 = axes[1]
    ax2.hist(cost_matrix.flatten(), bins=30, edgecolor='black', alpha=0.7, color='coral')
    ax2.set_xlabel('Cost Value', fontsize=12)
    ax2.set_ylabel('Frequency', fontsize=12)
    ax2.set_title('Distribution of Cost Values', fontsize=12)
    ax2.axvline(cost_matrix.mean(), color='red', linestyle='--', linewidth=2,
                label=f'Mean: {cost_matrix.mean():.1f}')
    ax2.legend(fontsize=11)

    # Adjust layout and save
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')

    print(f"\nâœ“ Figure saved to: {save_path}")

    # Show the plot
    plt.show()


def understand_solution_representation():
    """
    Explain the solution representation for the assignment problem.

    WHAT: Document how solutions are encoded.

    WHY: Choosing the right representation is crucial for the genetic algorithm.
         Permutation encoding naturally enforces the constraint that each drone
         is used exactly once.

    COURSE CONNECTION:
        - Your Presentation: "Representation: Solution = permutation list (length n),
          Position = area; Value = assigned drone"
        - Lecture 4: "Edge Recombination is a permutation-preserving crossover
          which was specifically designed for the TSP"
        - The key insight is that permutation problems require special operators!
    """
    print("\n" + "=" * 60)
    print("SOLUTION REPRESENTATION")
    print("=" * 60)

    print("""
    We use PERMUTATION ENCODING for this assignment problem.

    FORMAT: solution = [drone_for_area_0, drone_for_area_1, ..., drone_for_area_99]

    EXAMPLE (for n=5):
        solution = [2, 4, 0, 3, 1]

        This means:
        - Area 0 is assigned drone 2
        - Area 1 is assigned drone 4
        - Area 2 is assigned drone 0
        - Area 3 is assigned drone 3
        - Area 4 is assigned drone 1

    WHY PERMUTATION ENCODING?
        The key constraint is: each drone must be assigned to exactly ONE area.

        Using a permutation list automatically enforces this constraint:
        - Every number from 0 to n-1 appears exactly once
        - No repeats means no drone is double-assigned

    IMPORTANT FOR GENETIC OPERATORS:
        Standard crossover would break permutation validity!

        Bad example (standard one-point crossover):
            Parent 1: [2, 4, 0, 3, 1]
            Parent 2: [1, 3, 4, 0, 2]
            Crossover point: 2

            Child: [2, 4, | 4, 0, 2]  â† INVALID! (4 appears twice, 1 and 3 missing)

        This is why we need permutation-specific operators like:
        - Partially Matched Crossover (PMX) â† mentioned in your presentation
        - Order Crossover (OX)
        - Edge Recombination â† mentioned in Lecture 4
    """)


def main():
    """
    Main function to run all data understanding steps.
    """
    print("=" * 60)
    print("STEP 1: UNDERSTANDING THE ASSIGNMENT PROBLEM DATA")
    print("=" * 60)

    # Try to load the data from project directory
    try:
        n, cost_matrix = load_assignment_data(COST_FILE)
        analyze_cost_matrix(cost_matrix)

        # NEW: Visualize and save cost matrix
        visualize_cost_matrix(cost_matrix, COST_IMAGE)

    except FileNotFoundError:
        print(f"Note: Could not find file at {COST_FILE}")
        print("Creating synthetic example for demonstration...")
        n = 5
        cost_matrix = np.random.randint(1, 100, (n, n))
        analyze_cost_matrix(cost_matrix)

    # Explain the solution representation
    understand_solution_representation()

    print("\n" + "=" * 60)
    print("SUMMARY - STEP 1 COMPLETE")
    print("=" * 60)
    print(f"""
    âœ“ Cost matrix loaded from: {COST_FILE}
    âœ“ Visualization saved to: {COST_IMAGE}
    
    Cost Matrix (Objective 1 - MINIMIZE):
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Source: assign100.txt (OR-Library) â”‚
    â”‚  Size: 100 Ã— 100                    â”‚
    â”‚  Values: 1 to 100                   â”‚
    â”‚  Mean: ~51                          â”‚
    â”‚  Distribution: Uniform              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    NEXT STEPS:
    1. âœ“ We now understand the cost matrix structure
    2. â†’ Next: Create the synthetic detection probability matrix (Step 2)
    3. â†’ Then: Implement the objective functions (Step 3)
    4. â†’ Then: Implement NSGA-II algorithm (Step 4)
    """)


if __name__ == "__main__":
    main()


# END OF FILE
"""
COMP5012 Final Report - Step 2: Creating the Detection Probability Matrix
===========================================================================

WHAT WE'RE DOING:
    Creating a synthetic 100Ã—100 probability matrix P where P(i,j) represents
    the probability that drone i successfully detects a mine in area j.

WHY WE'RE DOING IT:
    The assessment requires TWO conflicting objectives for multi-objective
    optimization. We have:
    - Objective 1: Minimize cost (from assign100.txt)
    - Objective 2: Maximize detection probability (synthetic - approved by Dr. Ansell)

COURSE CONNECTION:
    - Your Presentation: "Dual Objectives: Objective 1: Maximize detection probability,
      Objective 2: Minimize cost"
    - Lecture 2 (Metaheuristics and MOOP): Multi-objective problems require 
      conflicting objectives to create interesting trade-offs
    - Dr. Ansell's email: Confirmed the approach of adding a second probability table
      for the likelihood of detection

DESIGN RATIONALE:
    We want the probability matrix to:
    1. Be in the range [0, 1] (valid probabilities)
    2. Have some structure (not purely random) to create realistic scenarios
    3. NOT be correlated with the cost matrix (to ensure objectives conflict)
"""

import numpy as np
import matplotlib.pyplot as plt

# Set random seed for reproducibility
np.random.seed(42)


def create_detection_probability_matrix(n, method='uniform'):
    """
    Create a synthetic detection probability matrix.

    WHAT: Generate nÃ—n matrix where P(i,j) = probability drone i detects mine in area j.

    WHY: We need a second objective function for multi-objective optimization.
         The probability values should be realistic (between 0 and 1).

    Parameters:
    -----------
    n : int
        Problem size (100 for assign100)
    method : str
        Method for generating probabilities:
        - 'uniform': Uniform random values in [0.3, 0.95]
        - 'structured': Drones have specializations (some better at certain areas)
        - 'beta': Uses beta distribution for more realistic probabilities

    COURSE CONNECTION:
        - Lecture 2: "defining objective functions" - we're designing the second objective
        - Your Presentation: "Maximize detection probability"
    """

    if method == 'uniform':
        # Simple uniform distribution
        # Range [0.3, 0.95] ensures no impossibly bad or perfect detection
        prob_matrix = np.random.uniform(0.3, 0.95, (n, n))

    elif method == 'structured':
        # More realistic: drones have strengths/weaknesses
        # Some drones are better at detecting in certain types of areas

        # Base probability for all drones
        base_prob = np.random.uniform(0.4, 0.6, (n, n))

        # Drone specialization factor (some drones are generally better)
        drone_skill = np.random.uniform(0.8, 1.2, (n, 1))

        # Area difficulty factor (some areas are easier to scan)
        area_difficulty = np.random.uniform(0.8, 1.2, (1, n))

        # Combine factors
        prob_matrix = base_prob * drone_skill * area_difficulty

        # Clip to valid probability range
        prob_matrix = np.clip(prob_matrix, 0.2, 0.98)

    elif method == 'beta':
        # Beta distribution is good for modeling probabilities
        # Parameters (alpha=2, beta=2) give bell-shaped distribution centered at 0.5
        # Parameters (alpha=5, beta=2) skew towards higher probabilities
        prob_matrix = np.random.beta(5, 2, (n, n))

    else:
        raise ValueError(f"Unknown method: {method}")

    return prob_matrix


def analyze_probability_matrix(prob_matrix, cost_matrix=None):
    """
    Analyze the probability matrix to understand its characteristics.

    WHAT: Generate statistics about the detection probabilities.

    WHY: Understanding the distribution helps us:
         1. Verify the matrix is sensible
         2. Check that it's not correlated with cost (objectives should conflict!)
         3. Understand what "good" vs "bad" detection looks like
    """
    print("\n" + "=" * 60)
    print("DETECTION PROBABILITY MATRIX ANALYSIS")
    print("=" * 60)

    print(f"\nMatrix shape: {prob_matrix.shape}")
    print(f"  Interpretation: {prob_matrix.shape[0]} drones Ã— {prob_matrix.shape[1]} areas")

    print(f"\nProbability statistics:")
    print(f"  Minimum probability: {prob_matrix.min():.4f}")
    print(f"  Maximum probability: {prob_matrix.max():.4f}")
    print(f"  Mean probability: {prob_matrix.mean():.4f}")
    print(f"  Std deviation: {prob_matrix.std():.4f}")

    print(f"\nSample of probability matrix (first 5Ã—5 corner):")
    print(np.round(prob_matrix[:5, :5], 3))

    # Find best and worst detection assignments
    max_idx = np.unravel_index(np.argmax(prob_matrix), prob_matrix.shape)
    min_idx = np.unravel_index(np.argmin(prob_matrix), prob_matrix.shape)

    print(f"\nBest detection: Drone {max_idx[0]} â†’ Area {max_idx[1]} (prob: {prob_matrix[max_idx]:.4f})")
    print(f"Worst detection: Drone {min_idx[0]} â†’ Area {min_idx[1]} (prob: {prob_matrix[min_idx]:.4f})")

    # Check correlation with cost matrix (if provided)
    if cost_matrix is not None:
        correlation = np.corrcoef(cost_matrix.flatten(), prob_matrix.flatten())[0, 1]
        print(f"\nCorrelation with cost matrix: {correlation:.4f}")
        print("  (We want this close to 0 to ensure objectives conflict!)")

        if abs(correlation) < 0.1:
            print("  âœ“ Good! Low correlation means objectives are largely independent.")
        elif abs(correlation) < 0.3:
            print("  âš  Moderate correlation - objectives may not conflict strongly.")
        else:
            print("  âœ— High correlation - consider regenerating with different seed.")


def visualize_probability_matrix(prob_matrix, save_path=None):
    """
    Create visualizations of the probability matrix.

    WHAT: Generate plots showing the distribution and structure of probabilities.

    WHY: Visualization helps us understand and communicate our design choices.
         The report will need figures showing the data characteristics.

    COURSE CONNECTION:
        - Assessment rubric mentions "visualisations demonstrating that the
          optimiser has found a suitable solution"
        - Understanding your data helps design better experiments
    """
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))

    # Heatmap of probabilities
    ax1 = axes[0]
    im = ax1.imshow(prob_matrix, cmap='YlOrRd', aspect='auto')
    ax1.set_xlabel('Area Index')
    ax1.set_ylabel('Drone Index')
    ax1.set_title('Detection Probability Matrix\nP(i,j) = Probability drone i detects mine in area j')
    plt.colorbar(im, ax=ax1, label='Detection Probability')

    # Histogram of all probability values
    ax2 = axes[1]
    ax2.hist(prob_matrix.flatten(), bins=30, edgecolor='black', alpha=0.7)
    ax2.set_xlabel('Detection Probability')
    ax2.set_ylabel('Frequency')
    ax2.set_title('Distribution of Detection Probabilities')
    ax2.axvline(prob_matrix.mean(), color='red', linestyle='--',
                label=f'Mean: {prob_matrix.mean():.3f}')
    ax2.legend()

    plt.tight_layout()

    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"\nFigure saved to: {save_path}")

    plt.close()


def save_probability_matrix(prob_matrix, filepath):
    """
    Save the probability matrix for later use.

    WHAT: Save matrix to a numpy file for reproducibility.

    WHY: We want to use the same probability matrix throughout all experiments
         for consistency. The report should use consistent data.
    """
    np.save(filepath, prob_matrix)
    print(f"\nProbability matrix saved to: {filepath}")
    print("  Load later with: prob_matrix = np.load(filepath)")


def main():
    """
    Main function to create and analyze the detection probability matrix.
    """
    print("=" * 60)
    print("STEP 2: CREATING DETECTION PROBABILITY MATRIX")
    print("=" * 60)

    # Load the cost matrix first (for correlation check)
    print("\nLoading cost matrix from assign100.txt...")
    with open(r"C:\Users\apzym\OneDrive\Desktop\PLYMOUTH\COMP5012\assign100.txt", 'r') as f:
        numbers = []
        for line in f:
            numbers.extend([int(x) for x in line.split()])
    n = numbers[0]
    cost_matrix = np.array(numbers[1:n * n + 1]).reshape(n, n)
    print(f"Cost matrix loaded: {cost_matrix.shape}")

    # Create the probability matrix using different methods
    print("\n" + "-" * 60)
    print("METHOD 1: Uniform Distribution")
    print("-" * 60)
    prob_uniform = create_detection_probability_matrix(n, method='uniform')
    analyze_probability_matrix(prob_uniform, cost_matrix)

    print("\n" + "-" * 60)
    print("METHOD 2: Beta Distribution (skewed towards higher probabilities)")
    print("-" * 60)
    prob_beta = create_detection_probability_matrix(n, method='beta')
    analyze_probability_matrix(prob_beta, cost_matrix)

    print("\n" + "-" * 60)
    print("METHOD 3: Structured (drones have specializations)")
    print("-" * 60)
    prob_structured = create_detection_probability_matrix(n, method='structured')
    analyze_probability_matrix(prob_structured, cost_matrix)

    # For the project, we'll use the beta distribution
    # It gives realistic probabilities skewed towards successful detection
    print("\n" + "=" * 60)
    print("SELECTED METHOD: Beta Distribution")
    print("=" * 60)
    print("""
    RATIONALE:
    - Beta distribution is commonly used for modeling probabilities
    - Parameters (alpha=5, beta=2) give realistic detection rates
    - Skewed towards higher probabilities (most drones can detect reasonably well)
    - Independent of cost matrix (low correlation ensures conflicting objectives)

    This is important for multi-objective optimization because:
    - Conflicting objectives create interesting trade-offs
    - The Pareto front will show meaningful choices
    - A decision maker can choose between cost and detection quality
    """)

    # Save the chosen probability matrix
    prob_matrix = prob_beta
    save_probability_matrix(prob_matrix, r'C:\Users\apzym\OneDrive\Desktop\PLYMOUTH\COMP5012\detection_probabilities.npy')

    # Create visualization
    visualize_probability_matrix(prob_matrix,r'C:\Users\apzym\OneDrive\Desktop\PLYMOUTH\COMP5012\probability_matrix.png')

    print("\n" + "=" * 60)
    print("NEXT STEPS:")
    print("=" * 60)
    print("""
    1. âœ“ Cost matrix loaded and understood
    2. âœ“ Detection probability matrix created and saved
    3. â†’ Next: Implement the objective functions (Step 3)
       - f1(solution) = total cost of assignment
       - f2(solution) = total detection probability (or negative, for minimization)
    4. â†’ Then: Implement NSGA-II algorithm (Step 4)
    """)


if __name__ == "__main__":
    main()

# END OF FILE

"""
COMP5012 Final Report - Step 3: Solution Representation & Objective Functions
===============================================================================

WHAT WE'RE DOING:
    Implementing the solution class and objective functions for the mine 
    detection assignment problem.

WHY WE'RE DOING IT:
    The objective functions are the foundation of any optimization problem.
    They define what we're trying to optimize and how we measure solution quality.

COURSE CONNECTION:
    - Assessment Brief: "You must write Python code that implements the objective 
      functions"
    - Lecture 2 (Metaheuristics and MOOP): Understanding how to define and evaluate
      objectives is fundamental to optimization
    - Your Presentation: "Dual Objectives: Objective 1: Maximize detection probability,
      Objective 2: Minimize cost"
    - Workshop 2 Model Answer: Shows class-based solution design pattern

MULTI-OBJECTIVE NOTE:
    Since we have TWO objectives, we need to handle them appropriately:
    - NSGA-II can handle both minimization objectives
    - We'll convert "maximize detection" to "minimize negative detection" 
      OR keep track of which objectives to minimize vs maximize
"""

import numpy as np
from typing import Tuple, List


class Solution:
    """
    Represents a solution to the mine detection assignment problem.

    WHAT: A solution is a permutation representing drone-to-area assignments.

    WHY: Encapsulating the solution in a class allows us to:
         1. Store both the assignment and its objective values together
         2. Add methods for evaluation, comparison, and manipulation
         3. Keep the code organized (important for the 25% implementation mark)

    COURSE CONNECTION:
        - Workshop 2 shows this class-based design pattern
        - Your Presentation: "Representation: Solution = permutation list (length n)"

    Attributes:
    -----------
    permutation : np.ndarray
        Array of length n where permutation[area] = drone assigned to that area
    objectives : tuple
        (cost, detection) values after evaluation
    rank : int
        Pareto rank from non-dominated sorting (used in NSGA-II)
    crowding_distance : float
        Crowding distance for diversity preservation (used in NSGA-II)
    """

    def __init__(self, permutation: np.ndarray):
        """
        Initialize a solution with a given permutation.

        Parameters:
        -----------
        permutation : np.ndarray
            Array where permutation[area] = drone assigned to that area
        """
        self.permutation = np.array(permutation)
        self.objectives = None  # (cost, detection) - set after evaluation
        self.rank = None  # Pareto rank - set during NSGA-II selection
        self.crowding_distance = None  # Set during NSGA-II selection

    def is_valid(self) -> bool:
        """
        Check if the solution is a valid permutation.

        WHAT: Verify that the solution satisfies all constraints.

        WHY: Invalid solutions waste computational resources and produce
             meaningless results. We should catch errors early.

        COURSE CONNECTION:
            - Your Presentation: "Constraints enforced by encoding: One drone
              per area; no repeats"
        """
        n = len(self.permutation)

        # Check 1: All values are within valid range [0, n-1]
        if not np.all((self.permutation >= 0) & (self.permutation < n)):
            return False

        # Check 2: All values are unique (no drone assigned twice)
        if len(np.unique(self.permutation)) != n:
            return False

        return True

    def evaluate(self, cost_matrix: np.ndarray, prob_matrix: np.ndarray):
        """
        Evaluate the solution's objective values.

        WHAT: Calculate both objective function values for this solution.

        WHY: Objective values determine solution quality and drive the
             optimization process.

        COURSE CONNECTION:
            - Lecture 2: Objective function evaluation is central to optimization
            - Your Presentation: "Dual Objectives"

        Parameters:
        -----------
        cost_matrix : np.ndarray
            nÃ—n matrix where cost_matrix[drone][area] = assignment cost
        prob_matrix : np.ndarray
            nÃ—n matrix where prob_matrix[drone][area] = detection probability

        Returns:
        --------
        tuple : (cost, detection)
            The objective values for this solution
        """
        n = len(self.permutation)

        # Objective 1: Total Cost (MINIMIZE)
        # Sum of c(drone_i, area_i) for all assignments
        total_cost = sum(
            cost_matrix[self.permutation[area], area]
            for area in range(n)
        )

        # Objective 2: Total Detection Probability (MAXIMIZE)
        # Sum of p(drone_i, area_i) for all assignments
        total_detection = sum(
            prob_matrix[self.permutation[area], area]
            for area in range(n)
        )

        # Store as tuple (cost, detection)
        # Note: For NSGA-II, we'll treat cost as minimize and detection as maximize
        # OR convert to (cost, -detection) to minimize both
        self.objectives = (total_cost, total_detection)

        return self.objectives

    def dominates(self, other: 'Solution') -> bool:
        """
        Check if this solution dominates another solution.

        WHAT: Pareto dominance comparison between two solutions.

        WHY: Pareto dominance is the core concept in multi-objective optimization.
             It determines which solutions are "better" without converting to
             a single objective.

        COURSE CONNECTION:
            - Lecture 2 (MOOP): "When a candidate solutions is considered, solutions
              in areas labelled e are equal, solutions in area b are better and
              solutions in area w are worse"
            - Lecture 4 (NSGA-II): "Rank solutions with non-dominated sorting"

        Definition:
            Solution A dominates Solution B if:
            1. A is no worse than B in all objectives
            2. A is strictly better than B in at least one objective

            For our problem:
            - Lower cost is better (minimize)
            - Higher detection is better (maximize)

        Parameters:
        -----------
        other : Solution
            The solution to compare against

        Returns:
        --------
        bool : True if self dominates other
        """
        if self.objectives is None or other.objectives is None:
            raise ValueError("Solutions must be evaluated before dominance check")

        cost_self, detect_self = self.objectives
        cost_other, detect_other = other.objectives

        # Check condition 1: self is no worse in all objectives
        no_worse_cost = cost_self <= cost_other  # Lower cost is better
        no_worse_detect = detect_self >= detect_other  # Higher detection is better
        no_worse = no_worse_cost and no_worse_detect

        # Check condition 2: self is strictly better in at least one objective
        strictly_better_cost = cost_self < cost_other
        strictly_better_detect = detect_self > detect_other
        strictly_better = strictly_better_cost or strictly_better_detect

        return no_worse and strictly_better

    def copy(self) -> 'Solution':
        """Create a deep copy of this solution."""
        new_solution = Solution(self.permutation.copy())
        if self.objectives is not None:
            new_solution.objectives = self.objectives
        new_solution.rank = self.rank
        new_solution.crowding_distance = self.crowding_distance
        return new_solution

    def __repr__(self):
        """String representation for debugging."""
        obj_str = f"({self.objectives[0]:.1f}, {self.objectives[1]:.3f})" if self.objectives else "unevaluated"
        return f"Solution(objectives={obj_str}, rank={self.rank})"


def create_random_solution(n: int) -> Solution:
    """
    Create a random valid solution (permutation).

    WHAT: Generate a random assignment of drones to areas.

    WHY: Random initialization is used to create the initial population
         in genetic algorithms.

    COURSE CONNECTION:
        - Lecture 4 (GA Flowchart): "Initialise" step creates initial population
        - Workshop 2: Shows random solution generation

    Parameters:
    -----------
    n : int
        Problem size (number of drones/areas)

    Returns:
    --------
    Solution : A randomly generated valid solution
    """
    permutation = np.random.permutation(n)
    return Solution(permutation)


def evaluate_assignment(permutation: np.ndarray,
                        cost_matrix: np.ndarray,
                        prob_matrix: np.ndarray) -> Tuple[float, float]:
    """
    Evaluate a permutation directly (functional interface).

    WHAT: Calculate objective values without creating a Solution object.

    WHY: Sometimes we just need the values quickly without object overhead.

    Parameters:
    -----------
    permutation : np.ndarray
        The assignment permutation
    cost_matrix : np.ndarray
        The cost matrix from assign100.txt
    prob_matrix : np.ndarray
        The detection probability matrix

    Returns:
    --------
    tuple : (total_cost, total_detection)
    """
    n = len(permutation)

    total_cost = sum(cost_matrix[permutation[area], area] for area in range(n))
    total_detection = sum(prob_matrix[permutation[area], area] for area in range(n))

    return total_cost, total_detection


# ============================================================================
# TESTING AND DEMONSTRATION
# ============================================================================

def test_solution_class():
    """
    Test the Solution class with examples.

    WHAT: Verify our implementation is correct.

    WHY: Testing is essential before building more complex algorithms.
         Bugs in the foundation will propagate to all results.

    COURSE CONNECTION:
        - Workshop 2 shows testing patterns with print statements
    """
    print("=" * 60)
    print("TESTING SOLUTION CLASS")
    print("=" * 60)

    # Create small test matrices (5Ã—5 for clarity)
    n = 5

    # Simple test cost matrix
    cost_matrix = np.array([
        [10, 20, 30, 40, 50],
        [15, 25, 35, 45, 55],
        [12, 22, 32, 42, 52],
        [18, 28, 38, 48, 58],
        [11, 21, 31, 41, 51]
    ])

    # Simple test probability matrix
    prob_matrix = np.array([
        [0.9, 0.8, 0.7, 0.6, 0.5],
        [0.85, 0.75, 0.65, 0.55, 0.45],
        [0.88, 0.78, 0.68, 0.58, 0.48],
        [0.82, 0.72, 0.62, 0.52, 0.42],
        [0.91, 0.81, 0.71, 0.61, 0.51]
    ])

    print("\nTest 1: Creating and validating a solution")
    print("-" * 40)
    sol1 = Solution(np.array([0, 1, 2, 3, 4]))  # Identity assignment
    print(f"Solution: {sol1.permutation}")
    print(f"Is valid: {sol1.is_valid()}")

    # Evaluate
    sol1.evaluate(cost_matrix, prob_matrix)
    print(f"Objectives: cost={sol1.objectives[0]}, detection={sol1.objectives[1]:.2f}")

    # Manual verification:
    # Cost: c(0,0) + c(1,1) + c(2,2) + c(3,3) + c(4,4) = 10+25+32+48+51 = 166
    # Detection: p(0,0) + p(1,1) + p(2,2) + p(3,3) + p(4,4) = 0.9+0.75+0.68+0.52+0.51 = 3.36
    print(f"Expected cost: 166, detection: 3.36")

    print("\nTest 2: Creating another solution for dominance comparison")
    print("-" * 40)
    sol2 = Solution(np.array([4, 3, 2, 1, 0]))  # Reversed assignment
    sol2.evaluate(cost_matrix, prob_matrix)
    print(f"Solution 2 permutation: {sol2.permutation}")
    print(f"Objectives: cost={sol2.objectives[0]}, detection={sol2.objectives[1]:.2f}")

    # Manual verification:
    # Cost: c(4,0) + c(3,1) + c(2,2) + c(1,3) + c(0,4) = 11+28+32+45+50 = 166
    # Detection: p(4,0) + p(3,1) + p(2,2) + p(1,3) + p(0,4) = 0.91+0.72+0.68+0.55+0.5 = 3.36

    print("\nTest 3: Pareto dominance")
    print("-" * 40)
    print(f"Does sol1 dominate sol2? {sol1.dominates(sol2)}")
    print(f"Does sol2 dominate sol1? {sol2.dominates(sol1)}")

    # Create a clearly dominated solution
    sol3 = Solution(np.array([0, 0, 0, 0, 0]))  # Invalid but let's test dominance concept
    # Actually, let's use a valid but worse solution

    print("\nTest 4: Invalid solution detection")
    print("-" * 40)
    invalid_sol = Solution(np.array([0, 0, 1, 2, 3]))  # Duplicate 0
    print(f"Invalid solution: {invalid_sol.permutation}")
    print(f"Is valid: {invalid_sol.is_valid()}")  # Should be False

    print("\nTest 5: Random solution generation")
    print("-" * 40)
    random_sol = create_random_solution(5)
    print(f"Random solution: {random_sol.permutation}")
    print(f"Is valid: {random_sol.is_valid()}")

    print("\n" + "=" * 60)
    print("ALL TESTS COMPLETED")
    print("=" * 60)


def demonstrate_objective_tradeoff():
    """
    Demonstrate the trade-off between cost and detection objectives.

    WHAT: Show that optimizing one objective may hurt the other.

    WHY: Understanding the trade-off is key to multi-objective optimization.
         This is what creates the Pareto front.

    COURSE CONNECTION:
        - Lecture 2: Multi-objective problems have conflicting objectives
        - Lecture 4: "The consequence is that now a decision maker can decide
          which solution to pick and look at the trade-offs between the objectives"
    """
    print("\n" + "=" * 60)
    print("DEMONSTRATING OBJECTIVE TRADE-OFF")
    print("=" * 60)

    # Load real data
    with open(r"C:\Users\apzym\OneDrive\Desktop\PLYMOUTH\COMP5012\assign100.txt", 'r') as f:
        numbers = []
        for line in f:
            numbers.extend([int(x) for x in line.split()])
    n = numbers[0]
    cost_matrix = np.array(numbers[1:n * n + 1]).reshape(n, n)

    # Load probability matrix
    prob_matrix = np.load(r'C:\Users\apzym\OneDrive\Desktop\PLYMOUTH\COMP5012\detection_probabilities.npy')

    print(f"\nProblem size: {n} drones, {n} areas")

    # Create several random solutions and evaluate them
    print("\nEvaluating 10 random solutions:")
    print("-" * 60)
    print(f"{'Solution':<10} {'Cost':<12} {'Detection':<12}")
    print("-" * 60)

    solutions = []
    for i in range(10):
        sol = create_random_solution(n)
        sol.evaluate(cost_matrix, prob_matrix)
        solutions.append(sol)
        print(f"{i + 1:<10} {sol.objectives[0]:<12.0f} {sol.objectives[1]:<12.3f}")

    # Find best for each objective
    best_cost = min(solutions, key=lambda s: s.objectives[0])
    best_detect = max(solutions, key=lambda s: s.objectives[1])

    print("\n" + "-" * 60)
    print(f"Best cost solution: Cost={best_cost.objectives[0]:.0f}, Detection={best_cost.objectives[1]:.3f}")
    print(f"Best detection solution: Cost={best_detect.objectives[0]:.0f}, Detection={best_detect.objectives[1]:.3f}")

    print("""
    OBSERVATION:
    The best cost solution may not have the best detection, and vice versa.
    This is the TRADE-OFF that multi-objective optimization explores.

    NSGA-II will find a set of solutions (Pareto front) that represent
    the best trade-offs between these conflicting objectives.
    """)


def main():
    """Run all tests and demonstrations."""
    print("=" * 60)
    print("STEP 3: SOLUTION CLASS & OBJECTIVE FUNCTIONS")
    print("=" * 60)

    # Run tests
    test_solution_class()

    # Demonstrate trade-off
    demonstrate_objective_tradeoff()

    print("\n" + "=" * 60)
    print("SUMMARY")
    print("=" * 60)
    print("""
    We have implemented:

    1. Solution class with:
       - Permutation representation
       - Validity checking
       - Objective function evaluation
       - Pareto dominance comparison

    2. Objective functions:
       - f1(solution) = total cost (MINIMIZE)
       - f2(solution) = total detection probability (MAXIMIZE)

    NEXT STEPS:
    -----------
    4. â†’ Implement genetic operators for permutations:
         - Tournament Selection
         - Partially Matched Crossover (PMX)
         - Swap Mutation

    5. â†’ Implement NSGA-II:
         - Non-dominated sorting
         - Crowding distance
         - Main evolutionary loop
    """)


if __name__ == "__main__":
    main()
"""
=============================================================================
COMP5012 - Computational Intelligence
Step 4: Genetic Operators for Multi-Objective Drone Assignment
=============================================================================

ğŸ“š LEARNING MODE - Î£ÏÎ½Î´ÎµÏƒÎ· Î¼Îµ Ï„Î¿ Î¥Î»Î¹ÎºÏŒ Ï„Î¿Ï… ÎœÎ±Î¸Î®Î¼Î±Ï„Î¿Ï‚:
-----------------------------------------------------
Î‘Ï€ÏŒ Ï„Î± Lecture Notes (Metaheuristics and MOOP):
    "Genetic operators are used to create new populations of solutions from 
     the old population. The operators fall into two categories: 
     mutation operators and crossover operators."

Î‘Ï€ÏŒ Ï„Î·Î½ Î Î±ÏÎ¿Ï…ÏƒÎ¯Î±ÏƒÎ® ÏƒÎ¿Ï…:
    - Selection: tournament
    - Crossover: order-based (Partially Matched Crossover)
    - Mutation: swap positions

Î“Î™Î‘Î¤Î™ Î‘Î¥Î¤ÎŸÎ™ ÎŸÎ™ OPERATORS;
-------------------------
Î¤Î¿ Ï€ÏÏŒÎ²Î»Î·Î¼Î¬ Î¼Î±Ï‚ ÎµÎ¯Î½Î±Î¹ PERMUTATION-BASED:
    - ÎšÎ¬Î¸Îµ Î»ÏÏƒÎ· ÎµÎ¯Î½Î±Î¹ Î¼Î¹Î± Î¼ÎµÏ„Î¬Î¸ÎµÏƒÎ· [0, 1, 2, ..., 99]
    - ÎšÎ¬Î¸Îµ drone ÎµÎ¼Ï†Î±Î½Î¯Î¶ÎµÏ„Î±Î¹ Î‘ÎšÎ¡Î™Î’Î©Î£ Î¼Î¯Î± Ï†Î¿ÏÎ¬
    - ÎšÎ¬Î¸Îµ area Ï€Î±Î¯ÏÎ½ÎµÎ¹ Î‘ÎšÎ¡Î™Î’Î©Î£ Î­Î½Î± drone

Î‘Ï…Ï„ÏŒ ÏƒÎ·Î¼Î±Î¯Î½ÎµÎ¹:
    âŒ One-point crossover Î¸Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÏƒÎµ Î‘ÎšÎ¥Î¡Î•Î£ Î»ÏÏƒÎµÎ¹Ï‚ (Î´Î¹Ï€Î»ÏŒÏ„Ï…Ï€Î±!)
    âœ… PMX Î´Î¹Î±Ï„Î·ÏÎµÎ¯ Ï„Î· Î¼Î¿Î½Î±Î´Î¹ÎºÏŒÏ„Î·Ï„Î± ÎºÎ¬Î¸Îµ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î¿Ï…
    âœ… Swap mutation ÎµÎ¯Î½Î±Î¹ Î±ÏƒÏ†Î±Î»Î®Ï‚ Î³Î¹Î± permutations
=============================================================================
"""

import numpy as np
import random
from typing import List, Tuple

# =============================================================================
# 1. TOURNAMENT SELECTION
# =============================================================================
"""
ğŸ“š LEARNING: Tournament Selection
---------------------------------
Î‘Ï€ÏŒ Ï„Î± Lecture Notes:
    "During the selection step, we only select a portion of the population 
     to reproduce for the creation of a new generation. Individual solutions 
     are selected through a fitness-based process so that better solutions 
     are more likely to be selected."

Î‘Ï€ÏŒ SPEA Algorithm (Lecture Notes):
    "Select parents from Population using binary tournament selection"

Î Î©Î£ Î›Î•Î™Î¤ÎŸÎ¥Î¡Î“Î•Î™:
1. Î•Ï€Î¹Î»Î­Î³Î¿Ï…Î¼Îµ Ï„Ï…Ï‡Î±Î¯Î± k Î¬Ï„Î¿Î¼Î± Î±Ï€ÏŒ Ï„Î¿Î½ Ï€Î»Î·Î¸Ï…ÏƒÎ¼ÏŒ (tournament size)
2. Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†Î¿Ï…Î¼Îµ Ï„Î¿ ÎšÎ‘Î›Î¥Î¤Î•Î¡ÎŸ Î±Ï€ÏŒ Î±Ï…Ï„Î¬
3. "ÎšÎ±Î»ÏÏ„ÎµÏÎ¿" = Ï‡Î±Î¼Î·Î»ÏŒÏ„ÎµÏÎ¿ rank (front) Î® Î¼ÎµÎ³Î±Î»ÏÏ„ÎµÏÎ¿ crowding distance

Î“Î™Î‘Î¤Î™ TOURNAMENT (ÎºÎ±Î¹ ÏŒÏ‡Î¹ roulette wheel);
- Î”Î¿Ï…Î»ÎµÏÎµÎ¹ ÎºÎ±Î»Î¬ Î¼Îµ multi-objective problems
- Î”ÎµÎ½ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ ÎºÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· fitness
- Î•ÏÎºÎ¿Î»Î· Ï€Î±ÏÎ±Î¼ÎµÏ„ÏÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Î¼Îµ tournament size
"""

def tournament_selection(population: List[np.ndarray],
                         ranks: np.ndarray,
                         crowding_distances: np.ndarray,
                         tournament_size: int = 2) -> np.ndarray:
    """
    Binary Tournament Selection Î³Î¹Î± NSGA-II.

    Î‘Ï€ÏŒ Ï„Î± Lecture Notes (NSGA-II):
        "Create a new offspring population from this new population using
         crowd tournament selection (it compares front ranking and then
         crowding distance to break ties)"

    Parameters:
    -----------
    population : List[np.ndarray]
        ÎŸ Ï€Î»Î·Î¸Ï…ÏƒÎ¼ÏŒÏ‚ Ï„Ï‰Î½ Î»ÏÏƒÎµÏ‰Î½ (ÎºÎ¬Î¸Îµ Î»ÏÏƒÎ· ÎµÎ¯Î½Î±Î¹ permutation)
    ranks : np.ndarray
        Î¤Î¿ Pareto front rank ÎºÎ¬Î¸Îµ Î»ÏÏƒÎ·Ï‚ (1 = best, non-dominated)
    crowding_distances : np.ndarray
        Î— crowding distance ÎºÎ¬Î¸Îµ Î»ÏÏƒÎ·Ï‚ (higher = better diversity)
    tournament_size : int
        Î ÏŒÏƒÎ± Î¬Ï„Î¿Î¼Î± ÏƒÏ…Î¼Î¼ÎµÏ„Î­Ï‡Î¿Ï…Î½ ÏƒÏ„Î¿ tournament (default: 2 = binary)

    Returns:
    --------
    np.ndarray : Î— Î½Î¹ÎºÎ®Ï„ÏÎ¹Î± Î»ÏÏƒÎ· (Î±Î½Ï„Î¯Î³ÏÎ±Ï†Î¿)
    """
    pop_size = len(population)

    # Î•Ï€Î¹Î»Î­Î³Î¿Ï…Î¼Îµ Ï„Ï…Ï‡Î±Î¯Î± tournament_size indices
    tournament_indices = np.random.choice(pop_size, size=tournament_size, replace=False)

    # Î’ÏÎ¯ÏƒÎºÎ¿Ï…Î¼Îµ Ï„Î¿Î½ Î½Î¹ÎºÎ·Ï„Î®
    # Î ÏÎ¿Ï„ÎµÏÎ±Î¹ÏŒÏ„Î·Ï„Î± 1: Î§Î±Î¼Î·Î»ÏŒÏ„ÎµÏÎ¿ rank (ÎºÎ±Î»ÏÏ„ÎµÏÎ¿ front)
    # Î ÏÎ¿Ï„ÎµÏÎ±Î¹ÏŒÏ„Î·Ï„Î± 2: ÎœÎµÎ³Î±Î»ÏÏ„ÎµÏÎ¿ crowding distance (Î´Î¹Î±Ï„Î®ÏÎ·ÏƒÎ· diversity)

    best_idx = tournament_indices[0]
    for idx in tournament_indices[1:]:
        # Î‘Î½ Î­Ï‡ÎµÎ¹ ÎºÎ±Î»ÏÏ„ÎµÏÎ¿ rank, Î½Î¹ÎºÎ¬ÎµÎ¹
        if ranks[idx] < ranks[best_idx]:
            best_idx = idx
        # Î‘Î½ Î­Ï‡ÎµÎ¹ Î¯Î´Î¹Î¿ rank, Î½Î¹ÎºÎ¬ÎµÎ¹ Î±Ï…Ï„ÏŒÏ‚ Î¼Îµ Î¼ÎµÎ³Î±Î»ÏÏ„ÎµÏÎ¿ crowding distance
        elif ranks[idx] == ranks[best_idx]:
            if crowding_distances[idx] > crowding_distances[best_idx]:
                best_idx = idx

    # Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†Î¿Ï…Î¼Îµ Î‘ÎÎ¤Î™Î“Î¡Î‘Î¦ÎŸ (Î³Î¹Î± Î½Î± Î¼Î·Î½ Î±Î»Î»Î¬Î¾Î¿Ï…Î¼Îµ Ï„Î¿Î½ Î±ÏÏ‡Î¹ÎºÏŒ Î³Î¿Î½Î­Î±)
    return population[best_idx].copy()


# =============================================================================
# 2. PMX CROSSOVER (Partially Matched Crossover)
# =============================================================================
"""
ğŸ“š LEARNING: PMX Crossover
--------------------------
Î‘Ï€ÏŒ Ï„Î·Î½ Î Î±ÏÎ¿Ï…ÏƒÎ¯Î±ÏƒÎ® ÏƒÎ¿Ï…:
    "Crossover: order-based (Partially Matched Crossover)"

Î‘Ï€ÏŒ Ï„Î± Lecture Notes:
    "Edge Recombination - This is a permutation-preserving crossover which 
     was specifically designed for the TSP in which round trips are encoded 
     as permutations of the cities."

PMX ÎµÎ¯Î½Î±Î¹ Ï€Î±ÏÏŒÎ¼Î¿Î¹Î¿ - Î´Î¹Î±Ï„Î·ÏÎµÎ¯ Ï„Î· Î´Î¿Î¼Î® Ï„Î·Ï‚ Î¼ÎµÏ„Î¬Î¸ÎµÏƒÎ·Ï‚!

Î Î©Î£ Î›Î•Î™Î¤ÎŸÎ¥Î¡Î“Î•Î™ Î¤ÎŸ PMX:
1. Î•Ï€Î¹Î»Î­Î³Î¿Ï…Î¼Îµ Î´ÏÎ¿ Ï„Ï…Ï‡Î±Î¯Î± ÏƒÎ·Î¼ÎµÎ¯Î± cut (crossover points)
2. Î‘Î½Ï„Î¹Î³ÏÎ¬Ï†Î¿Ï…Î¼Îµ Ï„Î¿ segment Î¼ÎµÏ„Î±Î¾Ï Ï„Î¿Ï…Ï‚ Î±Ï€ÏŒ parent1 ÏƒÏ„Î¿ child
3. Î“Î¹Î± Ï„Î¹Ï‚ Ï…Ï€ÏŒÎ»Î¿Î¹Ï€ÎµÏ‚ Î¸Î­ÏƒÎµÎ¹Ï‚, Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ¼Îµ mapping Î³Î¹Î± Î½Î± Î±Ï€Î¿Ï†ÏÎ³Î¿Ï…Î¼Îµ duplicates

Î Î‘Î¡Î‘Î”Î•Î™Î“ÎœÎ‘:
    Parent1: [1, 2, 3, 4, 5, 6, 7, 8]
    Parent2: [3, 7, 5, 1, 6, 8, 2, 4]
    
    Cut points: 3, 6 (segment: positions 3-5)
    
    Child starts: [_, _, _, 4, 5, 6, _, _]  (from parent1)
    
    Fill rest from parent2 using mapping...
    
    Result: Valid permutation!

Î“Î™Î‘Î¤Î™ PMX (ÎºÎ±Î¹ ÏŒÏ‡Î¹ one-point crossover);
- One-point crossover: [1,2,3] + [1,4,5] = [1,2,3,1,4,5] â† Î‘ÎšÎ¥Î¡ÎŸ! (duplicate 1)
- PMX: Î•Î³Î³Ï…Î¬Ï„Î±Î¹ valid permutation
"""

def pmx_crossover(parent1: np.ndarray, parent2: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    """
    Partially Matched Crossover (PMX) Î³Î¹Î± permutations.

    Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ Î”Î¥ÎŸ Ï€Î±Î¹Î´Î¹Î¬ Î±Ï€ÏŒ Î´ÏÎ¿ Î³Î¿Î½ÎµÎ¯Ï‚, Î´Î¹Î±Ï„Î·ÏÏÎ½Ï„Î±Ï‚
    Ï„Î· validity Ï„Î·Ï‚ Î¼ÎµÏ„Î¬Î¸ÎµÏƒÎ·Ï‚.

    Parameters:
    -----------
    parent1 : np.ndarray
        Î ÏÏÏ„Î¿Ï‚ Î³Î¿Î½Î­Î±Ï‚ (permutation)
    parent2 : np.ndarray
        Î”ÎµÏÏ„ÎµÏÎ¿Ï‚ Î³Î¿Î½Î­Î±Ï‚ (permutation)

    Returns:
    --------
    Tuple[np.ndarray, np.ndarray] : Î”ÏÎ¿ Ï€Î±Î¹Î´Î¹Î¬ (child1, child2)
    """
    n = len(parent1)

    # Î’Î®Î¼Î± 1: Î•Ï€Î¹Î»Î­Î³Î¿Ï…Î¼Îµ Î´ÏÎ¿ Ï„Ï…Ï‡Î±Î¯Î± crossover points
    point1, point2 = sorted(random.sample(range(n), 2))

    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÎ¼Îµ Ï„Î± Ï€Î±Î¹Î´Î¹Î¬ Î¼Îµ -1 (ÏƒÎ·Î¼Î±Î¯Î½ÎµÎ¹ "ÎºÎµÎ½ÏŒ")
    child1 = np.full(n, -1)
    child2 = np.full(n, -1)

    # Î’Î®Î¼Î± 2: Î‘Î½Ï„Î¹Î³ÏÎ¬Ï†Î¿Ï…Î¼Îµ Ï„Î¿ segment Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Î³Î¿Î½ÎµÎ¯Ï‚
    # child1 Ï€Î±Î¯ÏÎ½ÎµÎ¹ segment Î±Ï€ÏŒ parent1
    # child2 Ï€Î±Î¯ÏÎ½ÎµÎ¹ segment Î±Ï€ÏŒ parent2
    child1[point1:point2+1] = parent1[point1:point2+1]
    child2[point1:point2+1] = parent2[point1:point2+1]

    # Î’Î®Î¼Î± 3: Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÎ¼Îµ mapping Î³Î¹Î± conflict resolution
    # Î‘Ï…Ï„ÏŒ ÎµÎ¯Î½Î±Î¹ Ï„Î¿ "Î¼Î±Î³Î¹ÎºÏŒ" Ï„Î¿Ï… PMX!
    def fill_remaining(child, parent_segment, other_parent, point1, point2):
        """
        Î£Ï…Î¼Ï€Î»Î·ÏÏÎ½ÎµÎ¹ Ï„Î¹Ï‚ ÎºÎµÎ½Î­Ï‚ Î¸Î­ÏƒÎµÎ¹Ï‚ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏÎ½Ï„Î±Ï‚ mapping.
        """
        n = len(child)
        segment_values = set(parent_segment)

        # Î“Î¹Î± ÎºÎ¬Î¸Îµ Î¸Î­ÏƒÎ· ÎµÎºÏ„ÏŒÏ‚ Ï„Î¿Ï… segment
        for i in range(n):
            if i >= point1 and i <= point2:
                continue  # Skip segment positions

            # Î ÏÎ¿ÏƒÏ€Î±Î¸Î¿ÏÎ¼Îµ Î½Î± Ï€Î¬ÏÎ¿Ï…Î¼Îµ Ï„Î·Î½ Ï„Î¹Î¼Î® Î±Ï€ÏŒ other_parent
            value = other_parent[i]

            # Î‘Î½ Î· Ï„Î¹Î¼Î® Î®Î´Î· Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ ÏƒÏ„Î¿ segment, ÎºÎ¬Î½Î¿Ï…Î¼Îµ mapping
            while value in segment_values:
                # Î’ÏÎ¯ÏƒÎºÎ¿Ï…Î¼Îµ Ï€Î¿Ï ÎµÎ¯Î½Î±Î¹ Î±Ï…Ï„Î® Î· Ï„Î¹Î¼Î® ÏƒÏ„Î¿ segment Ï„Î¿Ï… parent
                idx = np.where(parent_segment == value)[0]
                if len(idx) > 0:
                    # Î Î±Î¯ÏÎ½Î¿Ï…Î¼Îµ Ï„Î·Î½ Î±Î½Ï„Î¯ÏƒÏ„Î¿Î¹Ï‡Î· Ï„Î¹Î¼Î® Î±Ï€ÏŒ other_parent
                    idx_in_segment = idx[0]
                    actual_pos = point1 + idx_in_segment
                    value = other_parent[actual_pos]
                else:
                    break

            child[i] = value

        return child

    # Î’Î®Î¼Î± 4: Î£Ï…Î¼Ï€Î»Î·ÏÏÎ½Î¿Ï…Î¼Îµ Ï„Î± Ï€Î±Î¹Î´Î¹Î¬
    segment1 = parent1[point1:point2+1]
    segment2 = parent2[point1:point2+1]

    child1 = fill_remaining(child1, segment1, parent2, point1, point2)
    child2 = fill_remaining(child2, segment2, parent1, point1, point2)

    return child1, child2


def pmx_crossover_simple(parent1: np.ndarray, parent2: np.ndarray) -> np.ndarray:
    """
    Î‘Ï€Î»Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î· Î­ÎºÎ´Î¿ÏƒÎ· PMX Ï€Î¿Ï… ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Î­Î½Î± Ï€Î±Î¹Î´Î¯.
    Î Î¹Î¿ ÎµÏÎºÎ¿Î»Î· ÏƒÏ„Î·Î½ ÎºÎ±Ï„Î±Î½ÏŒÎ·ÏƒÎ· ÎºÎ±Î¹ debugging.

    Î Î©Î£ Î›Î•Î™Î¤ÎŸÎ¥Î¡Î“Î•Î™ (Î’Î®Î¼Î±-Î²Î®Î¼Î±):
    1. Î‘Î½Ï„Î¹Î³ÏÎ¬Ï†Î¿Ï…Î¼Îµ segment Î±Ï€ÏŒ parent1 â†’ child
    2. Î“Î¹Î± ÎºÎ¬Î¸Îµ ÎºÎµÎ½Î® Î¸Î­ÏƒÎ·, Ï€Î±Î¯ÏÎ½Î¿Ï…Î¼Îµ Ï„Î¹Î¼Î® Î±Ï€ÏŒ parent2
    3. Î‘Î½ Î· Ï„Î¹Î¼Î® Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î®Î´Î·, Î²ÏÎ¯ÏƒÎºÎ¿Ï…Î¼Îµ Ï„Î·Î½ Ï€ÏÏÏ„Î· Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î·
    """
    n = len(parent1)

    # Î•Ï€Î¹Î»Î­Î³Î¿Ï…Î¼Îµ crossover points
    point1 = np.random.randint(0, n-1)
    point2 = np.random.randint(point1+1, n)

    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÎ¼Îµ child Î¼Îµ -1
    child = np.full(n, -1, dtype=int)

    # Î‘Î½Ï„Î¹Î³ÏÎ¬Ï†Î¿Ï…Î¼Îµ segment Î±Ï€ÏŒ parent1
    child[point1:point2] = parent1[point1:point2]

    # ÎšÏÎ±Ï„Î¬Î¼Îµ track Ï€Î¿Î¹ÎµÏ‚ Ï„Î¹Î¼Î­Ï‚ Î­Ï‡Î¿Ï…Î¼Îµ Î®Î´Î·
    used = set(child[point1:point2])

    # Î£Ï…Î¼Ï€Î»Î·ÏÏÎ½Î¿Ï…Î¼Îµ Î±Ï€ÏŒ parent2
    p2_idx = 0
    for i in range(n):
        if child[i] == -1:
            # Î’ÏÎ¯ÏƒÎºÎ¿Ï…Î¼Îµ Ï„Î·Î½ ÎµÏ€ÏŒÎ¼ÎµÎ½Î· Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î· Ï„Î¹Î¼Î® Î±Ï€ÏŒ parent2
            while parent2[p2_idx] in used:
                p2_idx += 1
            child[i] = parent2[p2_idx]
            used.add(parent2[p2_idx])
            p2_idx += 1

    return child


# =============================================================================
# 3. SWAP MUTATION
# =============================================================================
"""
ğŸ“š LEARNING: Swap Mutation
--------------------------
Î‘Ï€ÏŒ Ï„Î·Î½ Î Î±ÏÎ¿Ï…ÏƒÎ¯Î±ÏƒÎ® ÏƒÎ¿Ï…:
    "Mutation: swap positions"

Î‘Ï€ÏŒ Ï„Î± Lecture Notes:
    "A mutation operator will pick a random decision variable and modify 
     it in some way, this could be to 'flip' the variable to the opposite 
     state or to add a randomly generated value to it."
    
    "Mutation operators are good for exploiting good existing solutions."

Î“Î™Î‘ PERMUTATIONS:
- Î”ÎµÎ½ Î¼Ï€Î¿ÏÎ¿ÏÎ¼Îµ Î½Î± ÎºÎ¬Î½Î¿Ï…Î¼Îµ "flip" (Î¸Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®ÏƒÎ¿Ï…Î¼Îµ duplicate)
- Î‘Î½Ï„Î¯ Î±Ï…Ï„Î¿Ï, SWAP = Î±Î»Î»Î¬Î¶Î¿Ï…Î¼Îµ Î¸Î­ÏƒÎµÎ¹Ï‚ Î´ÏÎ¿ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Ï‰Î½

Î Î‘Î¡Î‘Î”Î•Î™Î“ÎœÎ‘:
    Before: [1, 2, 3, 4, 5]
    Swap positions 1 ÎºÎ±Î¹ 3
    After:  [1, 4, 3, 2, 5]
    
    âœ… Î Î±ÏÎ±Î¼Î­Î½ÎµÎ¹ valid permutation!

Î£ÎšÎŸÎ ÎŸÎ£ Î¤ÎŸÎ¥ MUTATION:
- Î•Î¹ÏƒÎ¬Î³ÎµÎ¹ DIVERSITY ÏƒÏ„Î¿Î½ Ï€Î»Î·Î¸Ï…ÏƒÎ¼ÏŒ
- Î‘Ï€Î¿Ï„ÏÎ­Ï€ÎµÎ¹ premature convergence
- Î•Ï€Î¹Ï„ÏÎ­Ï€ÎµÎ¹ EXPLORATION Î½Î­Ï‰Î½ Ï€ÎµÏÎ¹Î¿Ï‡ÏÎ½ Ï„Î¿Ï… search space
"""

def swap_mutation(solution: np.ndarray, mutation_rate: float = 0.1) -> np.ndarray:
    """
    Swap Mutation Î³Î¹Î± permutations.

    ÎœÎµ Ï€Î¹Î¸Î±Î½ÏŒÏ„Î·Ï„Î± mutation_rate, Î±Î»Î»Î¬Î¶ÎµÎ¹ Î¸Î­ÏƒÎµÎ¹Ï‚ Î´ÏÎ¿ Ï„Ï…Ï‡Î±Î¯Ï‰Î½ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Ï‰Î½.

    Parameters:
    -----------
    solution : np.ndarray
        Î— Î»ÏÏƒÎ· Ï€ÏÎ¿Ï‚ mutation (permutation)
    mutation_rate : float
        Î Î¹Î¸Î±Î½ÏŒÏ„Î·Ï„Î± Î½Î± Î³Î¯Î½ÎµÎ¹ mutation (default: 0.1 = 10%)

    Returns:
    --------
    np.ndarray : Î— (Ï€Î¹Î¸Î±Î½ÏÏ‚) mutated Î»ÏÏƒÎ·

    Î£Î·Î¼ÎµÎ¯Ï‰ÏƒÎ·: Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Î‘ÎÎ¤Î™Î“Î¡Î‘Î¦ÎŸ, Î´ÎµÎ½ Ï„ÏÎ¿Ï€Î¿Ï€Î¿Î¹ÎµÎ¯ Ï„Î¿ original
    """
    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÎ¼Îµ Î±Î½Ï„Î¯Î³ÏÎ±Ï†Î¿
    mutated = solution.copy()

    # Î•Î»Î­Î³Ï‡Î¿Ï…Î¼Îµ Î±Î½ Î¸Î± Î³Î¯Î½ÎµÎ¹ mutation
    if np.random.random() < mutation_rate:
        n = len(mutated)

        # Î•Ï€Î¹Î»Î­Î³Î¿Ï…Î¼Îµ Î´ÏÎ¿ Î”Î™Î‘Î¦ÎŸÎ¡Î•Î¤Î™ÎšÎ•Î£ Î¸Î­ÏƒÎµÎ¹Ï‚
        pos1, pos2 = np.random.choice(n, size=2, replace=False)

        # ÎšÎ¬Î½Î¿Ï…Î¼Îµ swap
        mutated[pos1], mutated[pos2] = mutated[pos2], mutated[pos1]

    return mutated


def multi_swap_mutation(solution: np.ndarray, num_swaps: int = 2) -> np.ndarray:
    """
    Î•ÎºÏ„ÎµÎ»ÎµÎ¯ Ï€Î¿Î»Î»Î±Ï€Î»Î¬ swaps (Ï€Î¹Î¿ aggressive mutation).

    Î§ÏÎ®ÏƒÎ¹Î¼Î¿ Î³Î¹Î± Î½Î± Î¾ÎµÏ†ÏÎ³Î¿Ï…Î¼Îµ Î±Ï€ÏŒ local optima.

    Parameters:
    -----------
    solution : np.ndarray
        Î— Î»ÏÏƒÎ· Ï€ÏÎ¿Ï‚ mutation
    num_swaps : int
        Î ÏŒÏƒÎ± swaps Î½Î± Î³Î¯Î½Î¿Ï…Î½

    Returns:
    --------
    np.ndarray : Î— mutated Î»ÏÏƒÎ·
    """
    mutated = solution.copy()
    n = len(mutated)

    for _ in range(num_swaps):
        pos1, pos2 = np.random.choice(n, size=2, replace=False)
        mutated[pos1], mutated[pos2] = mutated[pos2], mutated[pos1]

    return mutated


# =============================================================================
# 4. HELPER FUNCTIONS
# =============================================================================

def create_random_solution(n: int) -> np.ndarray:
    """
    Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ Î¼Î¹Î± Ï„Ï…Ï‡Î±Î¯Î± valid permutation.

    Parameters:
    -----------
    n : int
        Î¤Î¿ Î¼Î­Î³ÎµÎ¸Î¿Ï‚ Ï„Î·Ï‚ permutation

    Returns:
    --------
    np.ndarray : ÎœÎ¹Î± Ï„Ï…Ï‡Î±Î¯Î± Î¼ÎµÏ„Î¬Î¸ÎµÏƒÎ· [0, 1, 2, ..., n-1]
    """
    solution = np.arange(n)
    np.random.shuffle(solution)
    return solution


def is_valid_permutation(solution: np.ndarray, n: int) -> bool:
    """
    Î•Î»Î­Î³Ï‡ÎµÎ¹ Î±Î½ Î¼Î¹Î± Î»ÏÏƒÎ· ÎµÎ¯Î½Î±Î¹ valid permutation.

    ÎœÎ¹Î± valid permutation Ï€ÏÎ­Ï€ÎµÎ¹:
    1. ÎÎ± Î­Ï‡ÎµÎ¹ Î¼Î®ÎºÎ¿Ï‚ n
    2. ÎÎ± Ï€ÎµÏÎ¹Î­Ï‡ÎµÎ¹ ÎºÎ¬Î¸Îµ Î±ÏÎ¹Î¸Î¼ÏŒ Î±Ï€ÏŒ 0 Î­Ï‰Ï‚ n-1 Î±ÎºÏÎ¹Î²ÏÏ‚ Î¼Î¯Î± Ï†Î¿ÏÎ¬

    Parameters:
    -----------
    solution : np.ndarray
        Î— Î»ÏÏƒÎ· Ï€ÏÎ¿Ï‚ Î­Î»ÎµÎ³Ï‡Î¿
    n : int
        Î¤Î¿ Î±Î½Î±Î¼ÎµÎ½ÏŒÎ¼ÎµÎ½Î¿ Î¼Î­Î³ÎµÎ¸Î¿Ï‚

    Returns:
    --------
    bool : True Î±Î½ ÎµÎ¯Î½Î±Î¹ valid
    """
    if len(solution) != n:
        return False
    if set(solution) != set(range(n)):
        return False
    return True


# =============================================================================
# 5. TESTING - Î‘Ï‚ Î´Î¿ÎºÎ¹Î¼Î¬ÏƒÎ¿Ï…Î¼Îµ Ï„Î¿Ï…Ï‚ operators!
# =============================================================================

if __name__ == "__main__":
    print("=" * 70)
    print("STEP 4: Testing Genetic Operators")
    print("=" * 70)

    # ÎŸÏÎ¯Î¶Î¿Ï…Î¼Îµ Ï„Î¿ Î¼Î­Î³ÎµÎ¸Î¿Ï‚ Ï„Î¿Ï… Ï€ÏÎ¿Î²Î»Î®Î¼Î±Ï„Î¿Ï‚
    n = 100  # 100 areas, 100 drones

    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÎ¼Îµ test solutions
    np.random.seed(42)  # Î“Î¹Î± reproducibility

    print("\nğŸ“Š 1. Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Test Solutions")
    print("-" * 40)
    parent1 = create_random_solution(n)
    parent2 = create_random_solution(n)
    print(f"Parent 1 (Ï€ÏÏÏ„Î± 10): {parent1[:10]}")
    print(f"Parent 2 (Ï€ÏÏÏ„Î± 10): {parent2[:10]}")
    print(f"Valid permutation P1: {is_valid_permutation(parent1, n)}")
    print(f"Valid permutation P2: {is_valid_permutation(parent2, n)}")

    # Test PMX Crossover
    print("\nğŸ”€ 2. Testing PMX Crossover")
    print("-" * 40)
    child = pmx_crossover_simple(parent1, parent2)
    print(f"Child (Ï€ÏÏÏ„Î± 10): {child[:10]}")
    print(f"Valid permutation: {is_valid_permutation(child, n)}")

    # Verify uniqueness
    unique_values = len(set(child))
    print(f"Unique values: {unique_values} (Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎµÎ¯Î½Î±Î¹ {n})")

    # Test Swap Mutation
    print("\nğŸ§¬ 3. Testing Swap Mutation")
    print("-" * 40)
    original = child.copy()
    mutated = swap_mutation(child, mutation_rate=1.0)  # Force mutation

    # Î’ÏÎ¯ÏƒÎºÎ¿Ï…Î¼Îµ Î ÎŸÎ™Î•Î£ Î¸Î­ÏƒÎµÎ¹Ï‚ Î¬Î»Î»Î±Î¾Î±Î½
    changed_positions = np.where(original != mutated)[0]

    print(f"Valid permutation: {is_valid_permutation(mutated, n)}")
    print(f"Positions changed: {len(changed_positions)}")

    if len(changed_positions) == 2:
        pos1, pos2 = changed_positions
        print(f"\nğŸ”„ Swap Details:")
        print(f"   Position {pos1}: {original[pos1]} â†’ {mutated[pos1]}")
        print(f"   Position {pos2}: {original[pos2]} â†’ {mutated[pos2]}")
        print(f"\n   Î”Î·Î»Î±Î´Î®: Area {pos1} Î¬Î»Î»Î±Î¾Îµ drone Î±Ï€ÏŒ {original[pos1]} ÏƒÎµ {mutated[pos1]}")
        print(f"           Area {pos2} Î¬Î»Î»Î±Î¾Îµ drone Î±Ï€ÏŒ {original[pos2]} ÏƒÎµ {mutated[pos2]}")

    # Test Tournament Selection (Î¼Îµ dummy ranks ÎºÎ±Î¹ distances)
    print("\nğŸ† 4. Testing Tournament Selection")
    print("-" * 40)

    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÎ¼Îµ Î­Î½Î± Î¼Î¹ÎºÏÏŒ population Î³Î¹Î± testing
    pop_size = 10
    population = [create_random_solution(n) for _ in range(pop_size)]

    # Dummy ranks (1 = best front, higher = worse)
    ranks = np.array([1, 2, 1, 3, 2, 1, 3, 2, 1, 2])

    # Dummy crowding distances
    crowding_distances = np.random.random(pop_size)

    print(f"Population size: {pop_size}")
    print(f"Ranks: {ranks}")
    print(f"Crowding distances: {np.round(crowding_distances, 3)}")

    # ÎšÎ¬Î½Î¿Ï…Î¼Îµ selection Ï€Î¿Î»Î»Î­Ï‚ Ï†Î¿ÏÎ­Ï‚
    selection_counts = np.zeros(pop_size)
    for _ in range(1000):
        winner = tournament_selection(population, ranks, crowding_distances, tournament_size=2)
        # Î’ÏÎ¯ÏƒÎºÎ¿Ï…Î¼Îµ Ï€Î¿Î¹Î¿Ï‚ ÎºÎ­ÏÎ´Î¹ÏƒÎµ (Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î¿ Ï€ÏÏÏ„Î¿ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î¿)
        for i, p in enumerate(population):
            if np.array_equal(winner, p):
                selection_counts[i] += 1
                break

    print(f"\nSelection counts (1000 tournaments):")
    for i in range(pop_size):
        print(f"  Solution {i} (rank={ranks[i]}): {int(selection_counts[i])} times")

    print("\n" + "=" * 70)
    print("âœ… All Genetic Operators tested successfully!")
    print("=" * 70)

    # Summary Î³Î¹Î± Ï„Î¿ report
    print("\nğŸ“ SUMMARY Î³Î¹Î± Ï„Î¿ Report:")
    print("-" * 40)
    print("""
    ÎŸÎ¹ Genetic Operators Ï€Î¿Ï… Ï…Î»Î¿Ï€Î¿Î¹Î®Î¸Î·ÎºÎ±Î½:
    
    1. Tournament Selection (Binary)
       - Î•Ï€Î¹Î»Î­Î³ÎµÎ¹ 2 Ï„Ï…Ï‡Î±Î¯Î± Î¬Ï„Î¿Î¼Î±
       - ÎÎ¹ÎºÎ¬ÎµÎ¹ Î±Ï…Ï„ÏŒÏ‚ Î¼Îµ ÎºÎ±Î»ÏÏ„ÎµÏÎ¿ rank
       - Ties Î»ÏÎ½Î¿Î½Ï„Î±Î¹ Î¼Îµ crowding distance
       - Î£ÏÎ½Î´ÎµÏƒÎ·: NSGA-II lecture notes
    
    2. PMX Crossover
       - Permutation-safe crossover
       - Î”Î¹Î±Ï„Î·ÏÎµÎ¯ Ï„Î· Î¼Î¿Î½Î±Î´Î¹ÎºÏŒÏ„Î·Ï„Î± ÎºÎ¬Î¸Îµ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î¿Ï…
       - Î£ÏÎ½Î´ÎµÏƒÎ·: Presentation slide "Genetic Algorithm Design"
    
    3. Swap Mutation
       - Î‘Î»Î»Î¬Î¶ÎµÎ¹ Î¸Î­ÏƒÎµÎ¹Ï‚ 2 Ï„Ï…Ï‡Î±Î¯Ï‰Î½ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Ï‰Î½
       - Î•Î¹ÏƒÎ¬Î³ÎµÎ¹ diversity
       - Î£ÏÎ½Î´ÎµÏƒÎ·: Presentation slide "Genetic Algorithm Design"
    """)

    """
    =============================================================================
    COMP5012 - Computational Intelligence
    Step 5: NSGA-II Algorithm for Multi-Objective Drone Assignment
    =============================================================================

    ğŸ“š LEARNING MODE - Î£ÏÎ½Î´ÎµÏƒÎ· Î¼Îµ Ï„Î¿ Î¥Î»Î¹ÎºÏŒ Ï„Î¿Ï… ÎœÎ±Î¸Î®Î¼Î±Ï„Î¿Ï‚:
    -----------------------------------------------------
    Î‘Ï€ÏŒ Ï„Î± Lecture Notes (Metaheuristics and MOOP):

        "NSGA II stands for Non-dominated Sorting Genetic Algorithm 2 and was 
         published by Deb et al. in 2002. The algorithm is widely used in a 
         range of fields, and the original paper has been cited more than 
         40,000 times."

    Î¤Î± 3 KEY FEATURES Ï„Î¿Ï… NSGA-II:
        1. ELITIST PRINCIPLE - Î¿Î¹ ÎºÎ±Î»ÏÏ„ÎµÏÎµÏ‚ Î»ÏÏƒÎµÎ¹Ï‚ Ï€ÎµÏÎ½Î¬Î½Îµ ÏƒÏ„Î·Î½ ÎµÏ€ÏŒÎ¼ÎµÎ½Î· Î³ÎµÎ½Î¹Î¬
        2. CROWDING DISTANCE - Î´Î¹Î±Ï„Î·ÏÎµÎ¯ diversity (Ï€Î¿Î¹ÎºÎ¹Î»Î¯Î±)
        3. EMPHASISES NON-DOMINATING SOLUTIONS - Ï€ÏÎ¿Ï„ÎµÏÎ±Î¹ÏŒÏ„Î·Ï„Î± ÏƒÏ„Î¿ Pareto Front

    Î¤Î± Î’Î—ÎœÎ‘Î¤Î‘ Ï„Î¿Ï… Î±Î»Î³Î¿ÏÎ¯Î¸Î¼Î¿Ï…:
        1. "First, perform a non-dominating sorting in the combination of 
            parent and offspring populations and classify them by fronts."
        2. "Now fill a new population according to front ranking."
        3. "If the last front overflows, perform crowding sort."
        4. "Create a new offspring population using crowd tournament selection,
            crossover and mutation operators."
    =============================================================================
    """

    import numpy as np
    import matplotlib.pyplot as plt
    from typing import List, Tuple, Dict
    import random


    # =============================================================================
    # Î¦ÎŸÎ¡Î¤Î©Î£Î— Î”Î•Î”ÎŸÎœÎ•ÎÎ©Î ÎšÎ‘Î™ Î Î¡ÎŸÎ—Î“ÎŸÎ¥ÎœÎ•ÎÎŸÎ¥ ÎšÎ©Î”Î™ÎšÎ‘
    # =============================================================================

    def load_cost_matrix(filepath: str) -> np.ndarray:
        """Î¦Î¿ÏÏ„ÏÎ½ÎµÎ¹ Ï„Î¿Î½ cost matrix Î±Ï€ÏŒ Ï„Î¿ OR-Library Î±ÏÏ‡ÎµÎ¯Î¿."""
        with open(filepath, 'r') as f:
            lines = f.readlines()

        n = int(lines[0].strip())
        costs = []
        for line in lines[1:]:
            costs.extend([int(x) for x in line.split()])

        cost_matrix = np.array(costs).reshape(n, n)
        return cost_matrix


    def create_probability_matrix(n: int, alpha: float = 5, beta: float = 2,
                                  seed: int = 42) -> np.ndarray:
        """
        Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ Ï„Î¿Î½ probability matrix Î¼Îµ Beta distribution.

        Î‘Ï€ÏŒ Ï„Î·Î½ Ï€ÏÎ¿Î·Î³Î¿ÏÎ¼ÎµÎ½Î· Î´Î¿Ï…Î»ÎµÎ¹Î¬ (Step 2):
        - Beta(Î±=5, Î²=2) Î´Î¯Î½ÎµÎ¹ Ï„Î¹Î¼Î­Ï‚ skewed Ï€ÏÎ¿Ï‚ Ï…ÏˆÎ·Î»Î­Ï‚ Ï€Î¹Î¸Î±Î½ÏŒÏ„Î·Ï„ÎµÏ‚
        - Î‘Ï…Ï„ÏŒ Î´Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ conflict Î¼Îµ Ï„Î¿ cost (expensive drones = better detection)
        """
        np.random.seed(seed)
        return np.random.beta(alpha, beta, size=(n, n))


    # =============================================================================
    # SOLUTION CLASS - Î‘Î½Î±Ï€Î±ÏÎ¬ÏƒÏ„Î±ÏƒÎ· Î›ÏÏƒÎ·Ï‚
    # =============================================================================

    class Solution:
        """
        Î‘Î½Î±Ï€Î±ÏÎ¹ÏƒÏ„Î¬ Î¼Î¹Î± Î»ÏÏƒÎ· Ï„Î¿Ï… Ï€ÏÎ¿Î²Î»Î®Î¼Î±Ï„Î¿Ï‚.

        Attributes:
            permutation: np.ndarray - Î· Î±Î½Î¬Î¸ÎµÏƒÎ· (position=area, value=drone)
            objectives: Tuple[float, float] - (total_cost, negative_detection)
            rank: int - Pareto front rank (1 = best)
            crowding_distance: float - Î¼Î­Ï„ÏÎ¿ diversity
        """

        def __init__(self, permutation: np.ndarray):
            self.permutation = permutation.copy()
            self.objectives = None  # (cost, -detection) - BOTH MINIMIZED
            self.rank = None
            self.crowding_distance = 0.0

        def evaluate(self, cost_matrix: np.ndarray, prob_matrix: np.ndarray):
            """
            Î¥Ï€Î¿Î»Î¿Î³Î¯Î¶ÎµÎ¹ Ï„Î± objectives Ï„Î·Ï‚ Î»ÏÏƒÎ·Ï‚.

            Objective 1: MINIMIZE total cost
            Objective 2: MINIMIZE negative detection (= MAXIMIZE detection)

            Î£Î—ÎœÎ‘ÎÎ¤Î™ÎšÎŸ: ÎœÎµÏ„Î±Ï„ÏÎ­Ï€Î¿Ï…Î¼Îµ detection ÏƒÎµ Î±ÏÎ½Î·Ï„Î¹ÎºÏŒ Î³Î¹Î± Î½Î± Î³Î¯Î½ÎµÎ¹ minimization!
            """
            n = len(self.permutation)

            # Objective 1: Total Cost (minimize)
            total_cost = sum(cost_matrix[area, self.permutation[area]]
                             for area in range(n))

            # Objective 2: Total Detection Probability (maximize â†’ minimize negative)
            total_detection = sum(prob_matrix[area, self.permutation[area]]
                                  for area in range(n))

            # Î‘Ï€Î¿Î¸Î·ÎºÎµÏÎ¿Ï…Î¼Îµ Ï‰Ï‚ (cost, -detection) Î³Î¹Î± Î½Î± ÎºÎ¬Î½Î¿Ï…Î¼Îµ MINIMIZE ÎºÎ±Î¹ Ï„Î± Î´ÏÎ¿
            self.objectives = (total_cost, -total_detection)

            return self.objectives


    # =============================================================================
    # NON-DOMINATED SORTING
    # =============================================================================
    """
    ğŸ“š LEARNING: Non-dominated Sorting
    ----------------------------------
    Î‘Ï€ÏŒ Ï„Î± Lecture Notes:
        "Rank solutions with non-dominated sorting"
        "First, perform a non-dominating sorting in the combination of parent 
         and offspring populations and classify them by fronts."

    Î¤Î™ ÎšÎ‘ÎÎ•Î™:
    Î§Ï‰ÏÎ¯Î¶ÎµÎ¹ Ï„Î¿Î½ Ï€Î»Î·Î¸Ï…ÏƒÎ¼ÏŒ ÏƒÎµ "fronts" (Î¼Î­Ï„Ï‰Ï€Î±):
        - Front 1: Î›ÏÏƒÎµÎ¹Ï‚ Ï€Î¿Ï… Î´ÎµÎ½ ÎºÏ…ÏÎ¹Î±ÏÏ‡Î¿ÏÎ½Ï„Î±Î¹ Î±Ï€ÏŒ ÎºÎ±Î¼Î¯Î± Î¬Î»Î»Î· (BEST)
        - Front 2: Î›ÏÏƒÎµÎ¹Ï‚ Ï€Î¿Ï… ÎºÏ…ÏÎ¹Î±ÏÏ‡Î¿ÏÎ½Ï„Î±Î¹ Î¼ÏŒÎ½Î¿ Î±Ï€ÏŒ Ï„Î¿ Front 1
        - Front 3: Îº.Î¿.Îº.

    DOMINANCE (ÎšÏ…ÏÎ¹Î±ÏÏ‡Î¯Î±):
    Î›ÏÏƒÎ· A dominates Î›ÏÏƒÎ· B Î±Î½:
        - A ÎµÎ¯Î½Î±Î¹ ÎºÎ±Î»ÏÏ„ÎµÏÎ· Î® Î¯ÏƒÎ· ÏƒÎµ ÎŸÎ›ÎŸÎ¥Î£ Ï„Î¿Ï…Ï‚ ÏƒÏ„ÏŒÏ‡Î¿Ï…Ï‚ ÎšÎ‘Î™
        - A ÎµÎ¯Î½Î±Î¹ Î±Ï…ÏƒÏ„Î·ÏÎ¬ ÎºÎ±Î»ÏÏ„ÎµÏÎ· ÏƒÎµ Î¤ÎŸÎ¥Î›Î‘Î§Î™Î£Î¤ÎŸÎ Î•ÎÎ‘ ÏƒÏ„ÏŒÏ‡Î¿
    """


    def dominates(obj1: Tuple[float, float], obj2: Tuple[float, float]) -> bool:
        """
        Î•Î»Î­Î³Ï‡ÎµÎ¹ Î±Î½ Î· Î»ÏÏƒÎ· Î¼Îµ objectives obj1 ÎšÎ¥Î¡Î™Î‘Î¡Î§Î•Î™ Ï„Î·Î½ obj2.

        obj1 dominates obj2 Î±Î½:
        - obj1 <= obj2 ÏƒÎµ ÎŸÎ›ÎŸÎ¥Î£ Ï„Î¿Ï…Ï‚ ÏƒÏ„ÏŒÏ‡Î¿Ï…Ï‚ (ÎµÎ¯Î¼Î±ÏƒÏ„Îµ ÏƒÎµ minimization)
        - obj1 < obj2 ÏƒÎµ Î¤ÎŸÎ¥Î›Î‘Î§Î™Î£Î¤ÎŸÎ Î•ÎÎ‘ ÏƒÏ„ÏŒÏ‡Î¿

        Parameters:
        -----------
        obj1, obj2 : Tuple[float, float]
            Î¤Î± objectives Î´ÏÎ¿ Î»ÏÏƒÎµÏ‰Î½ (cost, -detection)

        Returns:
        --------
        bool : True Î±Î½ obj1 dominates obj2
        """
        better_in_all = all(o1 <= o2 for o1, o2 in zip(obj1, obj2))
        strictly_better_in_one = any(o1 < o2 for o1, o2 in zip(obj1, obj2))

        return better_in_all and strictly_better_in_one


    def fast_non_dominated_sort(population: List[Solution]) -> List[List[int]]:
        """
        Fast Non-dominated Sorting - O(MNÂ²) complexity.

        Î‘Ï€ÏŒ Ï„Î± Lecture Notes:
            "classify them by fronts"

        Parameters:
        -----------
        population : List[Solution]
            ÎŸ Ï€Î»Î·Î¸Ï…ÏƒÎ¼ÏŒÏ‚ Ï€ÏÎ¿Ï‚ Ï„Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ·

        Returns:
        --------
        List[List[int]] : Î›Î¯ÏƒÏ„Î± Î±Ï€ÏŒ fronts, ÎºÎ¬Î¸Îµ front Ï€ÎµÏÎ¹Î­Ï‡ÎµÎ¹ indices Î»ÏÏƒÎµÏ‰Î½
        """
        n = len(population)

        # Î“Î¹Î± ÎºÎ¬Î¸Îµ Î»ÏÏƒÎ·, ÎºÏÎ±Ï„Î¬Î¼Îµ:
        # - domination_count: Ï€ÏŒÏƒÎµÏ‚ Î»ÏÏƒÎµÎ¹Ï‚ Ï„Î·Î½ ÎºÏ…ÏÎ¹Î±ÏÏ‡Î¿ÏÎ½
        # - dominated_solutions: Ï€Î¿Î¹ÎµÏ‚ Î»ÏÏƒÎµÎ¹Ï‚ ÎºÏ…ÏÎ¹Î±ÏÏ‡ÎµÎ¯
        domination_count = [0] * n
        dominated_solutions = [[] for _ in range(n)]

        fronts = [[]]  # ÎÎµÎºÎ¹Î½Î¬Î¼Îµ Î¼Îµ ÎºÎµÎ½ÏŒ Front 1

        # Î’Î®Î¼Î± 1: Î¥Ï€Î¿Î»Î¿Î³Î¯Î¶Î¿Ï…Î¼Îµ domination Î³Î¹Î± ÎºÎ¬Î¸Îµ Î¶ÎµÏÎ³Î¿Ï‚
        for i in range(n):
            for j in range(n):
                if i == j:
                    continue

                if dominates(population[i].objectives, population[j].objectives):
                    # i dominates j
                    dominated_solutions[i].append(j)
                elif dominates(population[j].objectives, population[i].objectives):
                    # j dominates i
                    domination_count[i] += 1

        # Î’Î®Î¼Î± 2: Î’ÏÎ¯ÏƒÎºÎ¿Ï…Î¼Îµ Ï„Î¿ Front 1 (Î»ÏÏƒÎµÎ¹Ï‚ Î¼Îµ domination_count = 0)
        for i in range(n):
            if domination_count[i] == 0:
                population[i].rank = 1
                fronts[0].append(i)

        # Î’Î®Î¼Î± 3: Î’ÏÎ¯ÏƒÎºÎ¿Ï…Î¼Îµ Ï„Î± Ï…Ï€ÏŒÎ»Î¿Î¹Ï€Î± fronts
        current_front = 0
        while current_front < len(fronts) and len(fronts[current_front]) > 0:
            next_front = []

            for i in fronts[current_front]:
                for j in dominated_solutions[i]:
                    domination_count[j] -= 1
                    if domination_count[j] == 0:
                        population[j].rank = current_front + 2
                        next_front.append(j)

            current_front += 1
            if next_front:
                fronts.append(next_front)

        # Î‘Ï†Î±Î¹ÏÎ¿ÏÎ¼Îµ ÎºÎµÎ½Î¬ fronts
        fronts = [f for f in fronts if len(f) > 0]

        return fronts


    # =============================================================================
    # CROWDING DISTANCE
    # =============================================================================
    """
    ğŸ“š LEARNING: Crowding Distance
    ------------------------------
    Î‘Ï€ÏŒ Ï„Î± Lecture Notes:
        "Resolve ties with crowding distance"
        "crowding distance that is related to the density of solutions 
         around each solution. The less dense is preferred."

    Î¤Î™ ÎšÎ‘ÎÎ•Î™:
    ÎœÎµÏ„ÏÎ¬ÎµÎ¹ Ï€ÏŒÏƒÎ¿ "Î¼ÏŒÎ½Î·" ÎµÎ¯Î½Î±Î¹ Î¼Î¹Î± Î»ÏÏƒÎ· ÏƒÏ„Î¿Î½ objective space.
    - ÎœÎ•Î“Î‘Î›ÎŸ crowding distance = Î¼ÏŒÎ½Î·, ÏƒÎµ Î±ÏÎ±Î¹Î® Ï€ÎµÏÎ¹Î¿Ï‡Î® â†’ ÎšÎ‘Î›ÎŸ (Î¸Î­Î»Î¿Ï…Î¼Îµ diversity)
    - ÎœÎ™ÎšÎ¡ÎŸ crowding distance = Ï€Î¿Î»Î»Î­Ï‚ Î³ÎµÎ¹Ï„Î¿Î½Î¹ÎºÎ­Ï‚ Î»ÏÏƒÎµÎ¹Ï‚ â†’ ÎšÎ‘ÎšÎŸ

    Î¥Î ÎŸÎ›ÎŸÎ“Î™Î£ÎœÎŸÎ£:
    Î“Î¹Î± ÎºÎ¬Î¸Îµ objective:
    1. Î¤Î±Î¾Î¹Î½Î¿Î¼Î¿ÏÎ¼Îµ Ï„Î¹Ï‚ Î»ÏÏƒÎµÎ¹Ï‚
    2. ÎŸÎ¹ Î¬ÎºÏÎµÏ‚ (min, max) Ï€Î±Î¯ÏÎ½Î¿Ï…Î½ infinite distance
    3. ÎŸÎ¹ Ï…Ï€ÏŒÎ»Î¿Î¹Ï€ÎµÏ‚: distance = (next_obj - prev_obj) / (max_obj - min_obj)
    4. Î‘Î¸ÏÎ¿Î¯Î¶Î¿Ï…Î¼Îµ Î³Î¹Î± ÏŒÎ»Î± Ï„Î± objectives
    """


    def calculate_crowding_distance(population: List[Solution],
                                    front_indices: List[int]) -> None:
        """
        Î¥Ï€Î¿Î»Î¿Î³Î¯Î¶ÎµÎ¹ Ï„Î¿ crowding distance Î³Î¹Î± Ï„Î¹Ï‚ Î»ÏÏƒÎµÎ¹Ï‚ ÎµÎ½ÏŒÏ‚ front.

        Parameters:
        -----------
        population : List[Solution]
            ÎŸ Ï€Î»Î·Î¸Ï…ÏƒÎ¼ÏŒÏ‚
        front_indices : List[int]
            ÎŸÎ¹ indices Ï„Ï‰Î½ Î»ÏÏƒÎµÏ‰Î½ ÏƒÏ„Î¿ front
        """
        if len(front_indices) == 0:
            return

        # Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·
        for i in front_indices:
            population[i].crowding_distance = 0.0

        if len(front_indices) <= 2:
            # Î‘Î½ Î­Ï‡Î¿Ï…Î¼Îµ 1-2 Î»ÏÏƒÎµÎ¹Ï‚, Î´Î¯Î½Î¿Ï…Î¼Îµ infinite distance
            for i in front_indices:
                population[i].crowding_distance = float('inf')
            return

        num_objectives = 2  # cost ÎºÎ±Î¹ detection

        for obj_idx in range(num_objectives):
            # Î¤Î±Î¾Î¹Î½Î¿Î¼Î¿ÏÎ¼Îµ Î¼Îµ Î²Î¬ÏƒÎ· Î±Ï…Ï„ÏŒ Ï„Î¿ objective
            sorted_indices = sorted(front_indices,
                                    key=lambda i: population[i].objectives[obj_idx])

            # ÎŸÎ¹ Î¬ÎºÏÎµÏ‚ Ï€Î±Î¯ÏÎ½Î¿Ï…Î½ infinite distance
            population[sorted_indices[0]].crowding_distance = float('inf')
            population[sorted_indices[-1]].crowding_distance = float('inf')

            # Î¥Ï€Î¿Î»Î¿Î³Î¯Î¶Î¿Ï…Î¼Îµ Ï„Î¿ range Î³Î¹Î± ÎºÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·
            obj_min = population[sorted_indices[0]].objectives[obj_idx]
            obj_max = population[sorted_indices[-1]].objectives[obj_idx]

            if obj_max - obj_min == 0:
                continue  # Î‘Ï€Î¿Ï†Ï…Î³Î® division by zero

            # Î¥Ï€Î¿Î»Î¿Î³Î¯Î¶Î¿Ï…Î¼Îµ crowding distance Î³Î¹Î± Ï„Î¹Ï‚ ÎµÎ½Î´Î¹Î¬Î¼ÎµÏƒÎµÏ‚
            for i in range(1, len(sorted_indices) - 1):
                prev_obj = population[sorted_indices[i - 1]].objectives[obj_idx]
                next_obj = population[sorted_indices[i + 1]].objectives[obj_idx]

                population[sorted_indices[i]].crowding_distance += \
                    (next_obj - prev_obj) / (obj_max - obj_min)


    # =============================================================================
    # GENETIC OPERATORS (Î±Ï€ÏŒ Step 4)
    # =============================================================================

    def tournament_selection(population: List[Solution],
                             tournament_size: int = 2) -> Solution:
        """
        Binary Tournament Selection.

        Î‘Ï€ÏŒ Ï„Î± Lecture Notes:
            "crowd tournament selection (it compares front ranking and then
             crowding distance to break ties)"
        """
        contestants = random.sample(range(len(population)), tournament_size)

        best = contestants[0]
        for idx in contestants[1:]:
            # Î£ÏÎ³ÎºÏÎ¹ÏƒÎ·: Ï€ÏÏÏ„Î± rank, Î¼ÎµÏ„Î¬ crowding distance
            if population[idx].rank < population[best].rank:
                best = idx
            elif population[idx].rank == population[best].rank:
                if population[idx].crowding_distance > population[best].crowding_distance:
                    best = idx

        return Solution(population[best].permutation)


    def pmx_crossover(parent1: Solution, parent2: Solution) -> Solution:
        """
        Partially Matched Crossover (PMX) Î³Î¹Î± permutations.

        Î‘Ï€ÏŒ Ï„Î·Î½ Î Î±ÏÎ¿Ï…ÏƒÎ¯Î±ÏƒÎ·: "Crossover: order-based (Partially Matched Crossover)"
        """
        n = len(parent1.permutation)
        p1 = parent1.permutation
        p2 = parent2.permutation

        # Î•Ï€Î¹Î»Î­Î³Î¿Ï…Î¼Îµ crossover points
        point1 = np.random.randint(0, n - 1)
        point2 = np.random.randint(point1 + 1, n)

        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÎ¼Îµ child
        child = np.full(n, -1, dtype=int)

        # Î‘Î½Ï„Î¹Î³ÏÎ¬Ï†Î¿Ï…Î¼Îµ segment Î±Ï€ÏŒ parent1
        child[point1:point2] = p1[point1:point2]

        # ÎšÏÎ±Ï„Î¬Î¼Îµ track Ï€Î¿Î¹ÎµÏ‚ Ï„Î¹Î¼Î­Ï‚ Î­Ï‡Î¿Ï…Î¼Îµ
        used = set(child[point1:point2])

        # Î£Ï…Î¼Ï€Î»Î·ÏÏÎ½Î¿Ï…Î¼Îµ Î±Ï€ÏŒ parent2
        p2_idx = 0
        for i in range(n):
            if child[i] == -1:
                while p2[p2_idx] in used:
                    p2_idx += 1
                child[i] = p2[p2_idx]
                used.add(p2[p2_idx])
                p2_idx += 1

        return Solution(child)


    def swap_mutation(solution: Solution, mutation_rate: float = 0.1) -> Solution:
        """
        Swap Mutation Î³Î¹Î± permutations.

        Î‘Ï€ÏŒ Ï„Î·Î½ Î Î±ÏÎ¿Ï…ÏƒÎ¯Î±ÏƒÎ·: "Mutation: swap positions"
        """
        if np.random.random() < mutation_rate:
            perm = solution.permutation.copy()
            n = len(perm)
            pos1, pos2 = np.random.choice(n, size=2, replace=False)
            perm[pos1], perm[pos2] = perm[pos2], perm[pos1]
            return Solution(perm)
        return solution


    # =============================================================================
    # NSGA-II MAIN ALGORITHM
    # =============================================================================
    """
    ğŸ“š LEARNING: NSGA-II Main Loop
    ------------------------------
    Î‘Ï€ÏŒ Ï„Î± Lecture Notes:
        "The NSGA II algorithm has the following three key features:
         1. It uses an elitist principal, i.e. the elites of a population are 
            given the opportunity to be carried forward to the next generation.
         2. It uses an explicit diversity-preserving mechanism (crowding distance).
         3. It emphasises the non-dominating solutions."

    Î¤Î± Î²Î®Î¼Î±Ï„Î±:
        1. Initialise random population
        2. Evaluate population
        3. For each generation:
           a. Create offspring (selection, crossover, mutation)
           b. Combine parent + offspring
           c. Non-dominated sorting
           d. Select best N for next generation
        4. Return final Pareto front
    """


    class NSGA2:
        """
        NSGA-II Algorithm Implementation.

        Î’Î±ÏƒÎ¹ÏƒÎ¼Î­Î½Î¿ ÏƒÏ„Î¿ paper: Deb et al. (2002)
        """

        def __init__(self,
                     cost_matrix: np.ndarray,
                     prob_matrix: np.ndarray,
                     pop_size: int = 100,
                     num_generations: int = 200,
                     crossover_rate: float = 0.9,
                     mutation_rate: float = 0.1):
            """
            Parameters:
            -----------
            cost_matrix : np.ndarray
                ÎŸ Ï€Î¯Î½Î±ÎºÎ±Ï‚ ÎºÏŒÏƒÏ„Î¿Ï…Ï‚ (100x100)
            prob_matrix : np.ndarray
                ÎŸ Ï€Î¯Î½Î±ÎºÎ±Ï‚ Ï€Î¹Î¸Î±Î½Î¿Ï„Î®Ï„Ï‰Î½ detection (100x100)
            pop_size : int
                ÎœÎ­Î³ÎµÎ¸Î¿Ï‚ Ï€Î»Î·Î¸Ï…ÏƒÎ¼Î¿Ï
            num_generations : int
                Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ Î³ÎµÎ½ÎµÏÎ½
            crossover_rate : float
                Î Î¹Î¸Î±Î½ÏŒÏ„Î·Ï„Î± crossover
            mutation_rate : float
                Î Î¹Î¸Î±Î½ÏŒÏ„Î·Ï„Î± mutation
            """
            self.cost_matrix = cost_matrix
            self.prob_matrix = prob_matrix
            self.n = cost_matrix.shape[0]  # 100 areas/drones
            self.pop_size = pop_size
            self.num_generations = num_generations
            self.crossover_rate = crossover_rate
            self.mutation_rate = mutation_rate

            # Î“Î¹Î± tracking Ï„Î·Ï‚ ÎµÎ¾Î­Î»Î¹Î¾Î·Ï‚
            self.history = []

        def initialize_population(self) -> List[Solution]:
            """Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ Ï„Î¿Î½ Î±ÏÏ‡Î¹ÎºÏŒ Ï„Ï…Ï‡Î±Î¯Î¿ Ï€Î»Î·Î¸Ï…ÏƒÎ¼ÏŒ."""
            population = []
            for _ in range(self.pop_size):
                perm = np.random.permutation(self.n)
                sol = Solution(perm)
                sol.evaluate(self.cost_matrix, self.prob_matrix)
                population.append(sol)
            return population

        def create_offspring(self, population: List[Solution]) -> List[Solution]:
            """
            Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ offspring population.

            Î‘Ï€ÏŒ Ï„Î± Lecture Notes:
                "Create a new offspring population from this new population using
                 crowd tournament selection, crossover and mutation operators."
            """
            offspring = []

            while len(offspring) < self.pop_size:
                # Selection
                parent1 = tournament_selection(population)
                parent2 = tournament_selection(population)

                # Crossover
                if np.random.random() < self.crossover_rate:
                    child = pmx_crossover(parent1, parent2)
                else:
                    child = Solution(parent1.permutation.copy())

                # Mutation
                child = swap_mutation(child, self.mutation_rate)

                # Evaluate
                child.evaluate(self.cost_matrix, self.prob_matrix)
                offspring.append(child)

            return offspring

        def select_next_generation(self, combined: List[Solution]) -> List[Solution]:
            """
            Î•Ï€Î¹Î»Î­Î³ÎµÎ¹ Ï„Î¿Î½ ÎµÏ€ÏŒÎ¼ÎµÎ½Î¿ Ï€Î»Î·Î¸Ï…ÏƒÎ¼ÏŒ Î±Ï€ÏŒ Ï„Î¿Î½ combined (parents + offspring).

            Î‘Ï€ÏŒ Ï„Î± Lecture Notes:
                "Now fill a new population according to front ranking.
                 If the last front overflows, perform crowding sort that uses
                 the crowding distance."
            """
            # Non-dominated sorting
            fronts = fast_non_dominated_sort(combined)

            # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ crowding distance Î³Î¹Î± ÎºÎ¬Î¸Îµ front
            for front in fronts:
                calculate_crowding_distance(combined, front)

            # Î“Î­Î¼Î¹ÏƒÎ¼Î± Ï„Î¿Ï… Î½Î­Î¿Ï… Ï€Î»Î·Î¸Ï…ÏƒÎ¼Î¿Ï
            new_population = []
            front_idx = 0

            while len(new_population) + len(fronts[front_idx]) <= self.pop_size:
                # Î ÏÎ¿ÏƒÎ¸Î­Ï„Î¿Ï…Î¼Îµ Î¿Î»ÏŒÎºÎ»Î·ÏÎ¿ Ï„Î¿ front
                for i in fronts[front_idx]:
                    new_population.append(combined[i])
                front_idx += 1
                if front_idx >= len(fronts):
                    break

            # Î‘Î½ Ï‡ÏÎµÎ¹Î¬Î¶Î¿Î½Ï„Î±Î¹ ÎºÎ¹ Î¬Î»Î»ÎµÏ‚ Î»ÏÏƒÎµÎ¹Ï‚ Î±Ï€ÏŒ Ï„Î¿ Ï„ÎµÎ»ÎµÏ…Ï„Î±Î¯Î¿ front
            if len(new_population) < self.pop_size and front_idx < len(fronts):
                # Î¤Î±Î¾Î¹Î½Î¿Î¼Î¿ÏÎ¼Îµ Î¼Îµ Î²Î¬ÏƒÎ· crowding distance (descending)
                remaining = fronts[front_idx]
                remaining.sort(key=lambda i: combined[i].crowding_distance,
                               reverse=True)

                # Î ÏÎ¿ÏƒÎ¸Î­Ï„Î¿Ï…Î¼Îµ Ï„Î¹Ï‚ ÎºÎ±Î»ÏÏ„ÎµÏÎµÏ‚ (Î¼ÎµÎ³Î±Î»ÏÏ„ÎµÏÎ¿ crowding)
                for i in remaining:
                    if len(new_population) >= self.pop_size:
                        break
                    new_population.append(combined[i])

            return new_population

        def run(self) -> List[Solution]:
            """
            Î•ÎºÏ„ÎµÎ»ÎµÎ¯ Ï„Î¿Î½ NSGA-II Î±Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿.

            Returns:
            --------
            List[Solution] : Î¤Î¿ Ï„ÎµÎ»Î¹ÎºÏŒ Pareto front
            """
            print("=" * 60)
            print("NSGA-II Starting...")
            print("=" * 60)
            print(f"Population size: {self.pop_size}")
            print(f"Generations: {self.num_generations}")
            print(f"Problem size: {self.n} areas Ã— {self.n} drones")
            print("-" * 60)

            # Î’Î®Î¼Î± 1: Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·
            population = self.initialize_population()

            # Non-dominated sorting ÏƒÏ„Î¿Î½ Î±ÏÏ‡Î¹ÎºÏŒ Ï€Î»Î·Î¸Ï…ÏƒÎ¼ÏŒ
            fronts = fast_non_dominated_sort(population)
            for front in fronts:
                calculate_crowding_distance(population, front)

            # Î’Î®Î¼Î± 2: ÎšÏÏÎ¹Î¿Ï‚ Î²ÏÏŒÏ‡Î¿Ï‚ ÎµÎ¾Î­Î»Î¹Î¾Î·Ï‚
            for gen in range(self.num_generations):
                # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± offspring
                offspring = self.create_offspring(population)

                # Î£Ï…Î½Î´Ï…Î±ÏƒÎ¼ÏŒÏ‚ parent + offspring
                combined = population + offspring

                # Î•Ï€Î¹Î»Î¿Î³Î® ÎµÏ€ÏŒÎ¼ÎµÎ½Î·Ï‚ Î³ÎµÎ½Î¹Î¬Ï‚
                population = self.select_next_generation(combined)

                # Tracking progress
                pareto_front = [s for s in population if s.rank == 1]

                # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î³Î¹Î± visualization
                self.history.append({
                    'generation': gen + 1,
                    'pareto_size': len(pareto_front),
                    'best_cost': min(s.objectives[0] for s in pareto_front),
                    'best_detection': max(-s.objectives[1] for s in pareto_front)
                })

                # Progress update ÎºÎ¬Î¸Îµ 20 Î³ÎµÎ½Î¹Î­Ï‚
                if (gen + 1) % 20 == 0:
                    print(f"Generation {gen + 1:3d}: Pareto front size = {len(pareto_front)}, "
                          f"Best cost = {self.history[-1]['best_cost']:.0f}, "
                          f"Best detection = {self.history[-1]['best_detection']:.2f}")

            # Î¤ÎµÎ»Î¹ÎºÏŒ Pareto front
            final_pareto = [s for s in population if s.rank == 1]

            print("-" * 60)
            print(f"âœ… Optimization complete!")
            print(f"Final Pareto front size: {len(final_pareto)}")
            print("=" * 60)

            return final_pareto

        def plot_pareto_front(self, pareto_front: List[Solution],
                              save_path: str = None):
            """
            Visualize Ï„Î¿ Pareto front.

            Î‘Ï€ÏŒ Ï„Î± Lecture Notes:
                "When we have three objectives or less, we can also visualise
                 the trade-off between the solutions in a scatter plot."
            """
            # Î•Î¾Î±Î³Ï‰Î³Î® objectives
            costs = [s.objectives[0] for s in pareto_front]
            detections = [-s.objectives[1] for s in pareto_front]  # Î•Ï€Î±Î½Î±Ï†Î¿ÏÎ¬ ÏƒÎµ Î¸ÎµÏ„Î¹ÎºÏŒ

            plt.figure(figsize=(10, 8))
            plt.scatter(costs, detections, c='blue', s=50, alpha=0.7,
                        edgecolors='black', linewidths=0.5)

            plt.xlabel('Total Mission Cost (Minimize)', fontsize=12)
            plt.ylabel('Total Detection Probability (Maximize)', fontsize=12)
            plt.title('NSGA-II Pareto Front\nDrone Assignment Optimization',
                      fontsize=14, fontweight='bold')

            plt.grid(True, alpha=0.3)

            # Annotations Î³Î¹Î± extreme solutions
            min_cost_idx = np.argmin(costs)
            max_det_idx = np.argmax(detections)

            plt.annotate(f'Min Cost\n({costs[min_cost_idx]:.0f}, {detections[min_cost_idx]:.2f})',
                         xy=(costs[min_cost_idx], detections[min_cost_idx]),
                         xytext=(10, -20), textcoords='offset points',
                         fontsize=9, ha='left',
                         arrowprops=dict(arrowstyle='->', color='red'))

            plt.annotate(f'Max Detection\n({costs[max_det_idx]:.0f}, {detections[max_det_idx]:.2f})',
                         xy=(costs[max_det_idx], detections[max_det_idx]),
                         xytext=(10, 10), textcoords='offset points',
                         fontsize=9, ha='left',
                         arrowprops=dict(arrowstyle='->', color='green'))

            plt.tight_layout()

            if save_path:
                plt.savefig(save_path, dpi=150, bbox_inches='tight')
                print(f"ğŸ“Š Pareto front saved to: {save_path}")

            plt.show()

        def plot_convergence(self, save_path: str = None):
            """Visualize Ï„Î·Î½ ÎµÎ¾Î­Î»Î¹Î¾Î· Ï„Î¿Ï… Î±Î»Î³Î¿ÏÎ¯Î¸Î¼Î¿Ï…."""
            generations = [h['generation'] for h in self.history]
            pareto_sizes = [h['pareto_size'] for h in self.history]
            best_costs = [h['best_cost'] for h in self.history]
            best_detections = [h['best_detection'] for h in self.history]

            fig, axes = plt.subplots(1, 3, figsize=(15, 4))

            # Pareto front size
            axes[0].plot(generations, pareto_sizes, 'b-', linewidth=2)
            axes[0].set_xlabel('Generation')
            axes[0].set_ylabel('Pareto Front Size')
            axes[0].set_title('Pareto Front Growth')
            axes[0].grid(True, alpha=0.3)

            # Best cost
            axes[1].plot(generations, best_costs, 'r-', linewidth=2)
            axes[1].set_xlabel('Generation')
            axes[1].set_ylabel('Best Cost')
            axes[1].set_title('Best Cost Evolution')
            axes[1].grid(True, alpha=0.3)

            # Best detection
            axes[2].plot(generations, best_detections, 'g-', linewidth=2)
            axes[2].set_xlabel('Generation')
            axes[2].set_ylabel('Best Detection')
            axes[2].set_title('Best Detection Evolution')
            axes[2].grid(True, alpha=0.3)

            plt.tight_layout()

            if save_path:
                plt.savefig(save_path, dpi=150, bbox_inches='tight')
                print(f"ğŸ“ˆ Convergence plot saved to: {save_path}")

            plt.show()


    # =============================================================================
    # MAIN - Î•ÎšÎ¤Î•Î›Î•Î£Î—
    # =============================================================================

    if __name__ == "__main__":
        print("\n" + "=" * 70)
        print("STEP 5: NSGA-II for Multi-Objective Drone Assignment")
        print("=" * 70)

        # Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
        print("\nğŸ“‚ Loading data...")

        # Î ÏÎ¿ÏƒÏ€Î±Î¸Î¿ÏÎ¼Îµ Î½Î± Ï†Î¿ÏÏ„ÏÏƒÎ¿Ï…Î¼Îµ Î±Ï€ÏŒ Î´Î¹Î¬Ï†Î¿ÏÎµÏ‚ Ï„Î¿Ï€Î¿Î¸ÎµÏƒÎ¯ÎµÏ‚
        import os

        possible_paths = [
            r"C:\Users\apzym\OneDrive\Desktop\PLYMOUTH\COMP5012\assign100.txt"
        ]

        cost_matrix = None
        for path in possible_paths:
            if os.path.exists(path):
                cost_matrix = load_cost_matrix(path)
                print(f"âœ… Loaded cost matrix from: {path}")
                break

        if cost_matrix is None:
            print("âš ï¸ Could not find assign100.txt, creating synthetic data...")
            np.random.seed(42)
            cost_matrix = np.random.randint(1, 100, size=(100, 100))

        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± probability matrix
        prob_matrix = create_probability_matrix(100)
        print(f"âœ… Created probability matrix (100x100)")

        print(f"\nğŸ“Š Problem size: {cost_matrix.shape[0]} areas Ã— {cost_matrix.shape[1]} drones")
        print(f"   Cost range: [{cost_matrix.min()}, {cost_matrix.max()}]")
        print(f"   Detection range: [{prob_matrix.min():.3f}, {prob_matrix.max():.3f}]")

        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÎºÎ±Î¹ ÎµÎºÏ„Î­Î»ÎµÏƒÎ· NSGA-II
        nsga2 = NSGA2(
            cost_matrix=cost_matrix,
            prob_matrix=prob_matrix,
            pop_size=100,
            num_generations=100,  # ÎœÏ€Î¿ÏÎµÎ¯Ï‚ Î½Î± Î±Ï…Î¾Î®ÏƒÎµÎ¹Ï‚ Î³Î¹Î± ÎºÎ±Î»ÏÏ„ÎµÏÎ± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±
            crossover_rate=0.9,
            mutation_rate=0.1
        )

        # Î•ÎºÏ„Î­Î»ÎµÏƒÎ·
        pareto_front = nsga2.run()

        # Visualization
        print("\nğŸ“Š Creating visualizations...")
        nsga2.plot_pareto_front(pareto_front, save_path='pareto_front.png')
        nsga2.plot_convergence(save_path='convergence.png')

        # Summary
        print("\n" + "=" * 70)
        print("ğŸ“ SUMMARY")
        print("=" * 70)

        costs = [s.objectives[0] for s in pareto_front]
        detections = [-s.objectives[1] for s in pareto_front]

        print(f"\nPareto Front Statistics:")
        print(f"  - Number of solutions: {len(pareto_front)}")
        print(f"  - Cost range: [{min(costs):.0f}, {max(costs):.0f}]")
        print(f"  - Detection range: [{min(detections):.2f}, {max(detections):.2f}]")

        # Extreme solutions
        print(f"\nExtreme Solutions:")
        min_cost_idx = np.argmin(costs)
        max_det_idx = np.argmax(detections)

        print(f"  - Minimum Cost Solution:")
        print(f"      Cost = {costs[min_cost_idx]:.0f}")
        print(f"      Detection = {detections[min_cost_idx]:.2f}")

        print(f"  - Maximum Detection Solution:")
        print(f"      Cost = {costs[max_det_idx]:.0f}")
        print(f"      Detection = {detections[max_det_idx]:.2f}")

        print("\n" + "=" * 70)
        print("âœ… Step 5 Complete!")
        print("=" * 70)

        """
        ================================================================================
        COMP5012 - Step 6: Experimental Design (SKELETON)
        ================================================================================

        Î£ÎšÎŸÎ ÎŸÎ£: Î‘Ï…Ï„ÏŒÏ‚ Î¿ ÎºÏÎ´Î¹ÎºÎ±Ï‚ ÎµÎ¯Î½Î±Î¹ Î¿ ÏƒÎºÎµÎ»ÎµÏ„ÏŒÏ‚ Î³Î¹Î± Ï„Î± Ï€ÎµÎ¹ÏÎ¬Î¼Î±Ï„Î¬ ÏƒÎ¿Ï….
                Î•ÏƒÏ Î¸Î± Î±Î»Î»Î¬Î¾ÎµÎ¹Ï‚ Ï„Î¹Ï‚ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï…Ï‚ Î³Î¹Î± Î½Î± Î´ÎµÎ¹Ï‚ Ï€ÏÏ‚ ÎµÏ€Î·ÏÎµÎ¬Î¶Î¿Ï…Î½ Ï„Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±.

        COURSE CONNECTION:
        - Lecture 4: "Evaluating MOEAs" - Î ÏÏ‚ Î±Î¾Î¹Î¿Î»Î¿Î³Î¿ÏÎ¼Îµ multi-objective Î±Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Ï…Ï‚
        - Workshop 3: Experimental design Î¼Îµ multiple runs
        - Assessment Brief: "Good experimental design with clear rationale" (10%)

        Î¤Î™ Î˜Î‘ ÎœÎ‘Î˜Î•Î™Î£:
        1. Î“Î¹Î±Ï„Î¯ Ï„ÏÎ­Ï‡Î¿Ï…Î¼Îµ Ï€Î¿Î»Î»Î¬ runs (statistical significance)
        2. Î ÏÏ‚ Î¿Î¹ Ï€Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹ ÎµÏ€Î·ÏÎµÎ¬Î¶Î¿Ï…Î½ Ï„Î·Î½ Î±Ï€ÏŒÎ´Î¿ÏƒÎ·
        3. Î ÏÏ‚ Î½Î± Î±Î½Î±Î»ÏÎµÎ¹Ï‚ convergence

        ================================================================================
        ÎŸÎ”Î—Î“Î™Î•Î£ Î§Î¡Î—Î£Î—Î£:
        1. Î ÏÏÏ„Î± Ï„ÏÎ­Î¾Îµ Ï„Î¿Î½ ÎºÏÎ´Î¹ÎºÎ± ÏŒÏ€Ï‰Ï‚ ÎµÎ¯Î½Î±Î¹ Î³Î¹Î± Î½Î± Î´ÎµÎ¹Ï‚ ÏŒÏ„Î¹ Î´Î¿Ï…Î»ÎµÏÎµÎ¹
        2. ÎœÎµÏ„Î¬ Î¬Î»Î»Î±Î¾Îµ Ï„Î¹Ï‚ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï…Ï‚ ÏƒÏ„Î¿ SECTION: Î Î‘Î¡Î‘ÎœÎ•Î¤Î¡ÎŸÎ™ Î ÎŸÎ¥ Î‘Î›Î›Î‘Î–Î•Î™Î£ Î•Î£Î¥
        3. Î Î±ÏÎ±Ï„Î®ÏÎ·ÏƒÎµ Ï€ÏÏ‚ Î±Î»Î»Î¬Î¶Î¿Ï…Î½ Ï„Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±
        ================================================================================
        """

        import numpy as np
        import matplotlib.pyplot as plt
        import random
        import time


        # ============================================================
        # SECTION: Î¦ÎŸÎ¡Î¤Î©Î£Î— Î”Î•Î”ÎŸÎœÎ•ÎÎ©Î (Î‘Ï…Ï„Î¬ Ï„Î± Î­Ï‡ÎµÎ¹Ï‚ Î®Î´Î· Î±Ï€ÏŒ Steps 1-5)
        # ============================================================

        def load_cost_matrix(filepath):
            """Î¦ÏŒÏÏ„Ï‰ÏƒÎ· cost matrix Î±Ï€ÏŒ Ï„Î¿ assign100.txt"""
            with open(filepath, 'r') as f:
                lines = f.readlines()
            n = int(lines[0].strip())
            values = []
            for line in lines[1:]:
                values.extend([int(x) for x in line.split()])
            return np.array(values).reshape(n, n)


        def generate_probability_matrix(n, seed=42):
            """
            Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± probability matrix Î¼Îµ Beta(5,2) distribution

            Î“Î™Î‘Î¤Î™ BETA(5,2):
            - Î”Î¯Î½ÎµÎ¹ Ï„Î¹Î¼Î­Ï‚ 0-1 (Ï€Î¹Î¸Î±Î½ÏŒÏ„Î·Ï„ÎµÏ‚)
            - Skewed Ï€ÏÎ¿Ï‚ Ï…ÏˆÎ·Î»Î­Ï‚ Ï„Î¹Î¼Î­Ï‚ (ÏÎµÎ±Î»Î¹ÏƒÏ„Î¹ÎºÏŒ Î³Î¹Î± detection)
            - Course Link: Step 2 discussion
            """
            np.random.seed(seed)
            return np.random.beta(5, 2, size=(n, n))


        # ============================================================
        # SECTION: SOLUTION CLASS (Î±Ï€ÏŒ Step 3)
        # ============================================================

        class Solution:
            def __init__(self, permutation, cost_matrix, prob_matrix):
                self.permutation = np.array(permutation)
                self.cost = sum(cost_matrix[drone, area]
                                for area, drone in enumerate(self.permutation))
                self.detection = sum(prob_matrix[drone, area]
                                     for area, drone in enumerate(self.permutation))
                self.rank = None
                self.crowding_distance = 0


        def dominates(sol1, sol2):
            """
            Pareto Dominance: sol1 ÎºÏ…ÏÎ¹Î±ÏÏ‡ÎµÎ¯ sol2 Î±Î½:
            - Î•Î¯Î½Î±Î¹ ÎºÎ±Î»ÏÏ„ÎµÏÎ· Î® Î¯ÏƒÎ· ÏƒÎµ ÎŸÎ›Î‘ Ï„Î± objectives
            - Î•Î¯Î½Î±Î¹ Î‘Î¥Î£Î¤Î—Î¡Î‘ ÎºÎ±Î»ÏÏ„ÎµÏÎ· ÏƒÎµ Î¤ÎŸÎ¥Î›Î‘Î§Î™Î£Î¤ÎŸÎ Î•ÎÎ‘

            Course Link: Lecture 4 - Pareto Dominance definition
            """
            better_cost = sol1.cost <= sol2.cost
            better_detection = sol1.detection >= sol2.detection
            strictly_better = (sol1.cost < sol2.cost) or (sol1.detection > sol2.detection)
            return better_cost and better_detection and strictly_better


        # ============================================================
        # SECTION: GENETIC OPERATORS (Î±Ï€ÏŒ Step 4)
        # ============================================================

        def tournament_selection(population, tournament_size=2):
            """
            Binary Tournament Selection

            Î Î©Î£ Î”ÎŸÎ¥Î›Î•Î¥Î•Î™:
            1. Î”Î¹Î¬Î»ÎµÎ¾Îµ Ï„Ï…Ï‡Î±Î¯Î± 2 Î»ÏÏƒÎµÎ¹Ï‚
            2. Î•Ï€Î­ÏƒÏ„ÏÎµÏˆÎµ Î±Ï…Ï„Î® Î¼Îµ Ï„Î¿ ÎºÎ±Î»ÏÏ„ÎµÏÎ¿ rank
            3. Î‘Î½ Î¯Î´Î¹Î¿ rank, ÎµÏ€Î­ÏƒÏ„ÏÎµÏˆÎµ Î±Ï…Ï„Î® Î¼Îµ Î¼ÎµÎ³Î±Î»ÏÏ„ÎµÏÎ¿ crowding distance

            Course Link: Lecture 4 - NSGA-II selection
            """
            selected = random.sample(population, tournament_size)
            selected.sort(key=lambda x: (x.rank, -x.crowding_distance))
            return selected[0]


        def pmx_crossover(parent1, parent2):
            """
            Partially Matched Crossover (PMX)

            Î“Î™Î‘Î¤Î™ PMX:
            - Î”Î¹Î±Ï„Î·ÏÎµÎ¯ Ï„Î·Î½ ÎµÎ³ÎºÏ…ÏÏŒÏ„Î·Ï„Î± Ï„Î¿Ï… permutation
            - ÎšÎ¬Î¸Îµ drone ÎµÎ¼Ï†Î±Î½Î¯Î¶ÎµÏ„Î±Î¹ Î‘ÎšÎ¡Î™Î’Î©Î£ Î¼Î¯Î± Ï†Î¿ÏÎ¬

            Course Link: Lecture 4 - Permutation crossover operators
            """
            n = len(parent1.permutation)
            child1 = np.full(n, -1)
            child2 = np.full(n, -1)

            # Î”Î¹Î¬Î»ÎµÎ¾Îµ 2 crossover points
            cx1, cx2 = sorted(random.sample(range(n), 2))

            # Î‘Î½Ï„Î­Î³ÏÎ±ÏˆÎµ Ï„Î¿ segment
            child1[cx1:cx2 + 1] = parent1.permutation[cx1:cx2 + 1]
            child2[cx1:cx2 + 1] = parent2.permutation[cx1:cx2 + 1]

            # Î£Ï…Î¼Ï€Î»Î®ÏÏ‰ÏƒÎµ Ï„Î± Ï…Ï€ÏŒÎ»Î¿Î¹Ï€Î±
            def fill(child, donor):
                for i in range(n):
                    if child[i] == -1:
                        value = donor[i]
                        while value in child:
                            idx = np.where(donor == value)[0][0]
                            value = child[idx] if child[idx] != -1 else donor[idx]
                            if value == donor[i]:
                                for v in donor:
                                    if v not in child:
                                        value = v
                                        break
                        child[i] = value

            fill(child1, parent2.permutation)
            fill(child2, parent1.permutation)
            return child1, child2


        def swap_mutation(permutation, mutation_rate):
            """
            Swap Mutation

            Î Î©Î£ Î”ÎŸÎ¥Î›Î•Î¥Î•Î™:
            - ÎœÎµ Ï€Î¹Î¸Î±Î½ÏŒÏ„Î·Ï„Î± mutation_rate, Î±Î½Ï„Î¬Î»Î»Î±Î¾Îµ 2 Ï„Ï…Ï‡Î±Î¯ÎµÏ‚ Î¸Î­ÏƒÎµÎ¹Ï‚
            - Î”Î¹Î±Ï„Î·ÏÎµÎ¯ permutation validity

            Course Link: Lecture 4 - Mutation operators for permutations
            """
            mutated = permutation.copy()
            if random.random() < mutation_rate:
                i, j = random.sample(range(len(mutated)), 2)
                mutated[i], mutated[j] = mutated[j], mutated[i]
            return mutated


        # ============================================================
        # SECTION: NSGA-II ALGORITHM (Î±Ï€ÏŒ Step 5)
        # ============================================================

        def non_dominated_sorting(population):
            """
            Fast Non-dominated Sorting

            Î¤Î™ ÎšÎ‘ÎÎ•Î™:
            - Î§Ï‰ÏÎ¯Î¶ÎµÎ¹ Ï„Î¿Î½ Ï€Î»Î·Î¸Ï…ÏƒÎ¼ÏŒ ÏƒÎµ "fronts"
            - Front 0: ÎŸÎ¹ ÎºÎ±Î»ÏÏ„ÎµÏÎµÏ‚ Î»ÏÏƒÎµÎ¹Ï‚ (ÎºÎ±Î½ÎµÎ¯Ï‚ Î´ÎµÎ½ Ï„Î¹Ï‚ ÎºÏ…ÏÎ¹Î±ÏÏ‡ÎµÎ¯)
            - Front 1: ÎšÏ…ÏÎ¹Î±ÏÏ‡Î¿ÏÎ½Ï„Î±Î¹ Î¼ÏŒÎ½Î¿ Î±Ï€ÏŒ Front 0
            - ÎºÎ»Ï€...

            Course Link: Lecture 4 - NSGA-II non-dominated sorting
            """
            n = len(population)
            domination_count = [0] * n
            dominated_solutions = [[] for _ in range(n)]
            fronts = [[]]

            for i in range(n):
                for j in range(i + 1, n):
                    if dominates(population[i], population[j]):
                        dominated_solutions[i].append(j)
                        domination_count[j] += 1
                    elif dominates(population[j], population[i]):
                        dominated_solutions[j].append(i)
                        domination_count[i] += 1

            for i in range(n):
                if domination_count[i] == 0:
                    population[i].rank = 0
                    fronts[0].append(i)

            current = 0
            while fronts[current]:
                next_front = []
                for i in fronts[current]:
                    for j in dominated_solutions[i]:
                        domination_count[j] -= 1
                        if domination_count[j] == 0:
                            population[j].rank = current + 1
                            next_front.append(j)
                current += 1
                fronts.append(next_front)

            return fronts[:-1]


        def crowding_distance(population, front_indices):
            """
            Crowding Distance Calculation

            Î¤Î™ ÎšÎ‘ÎÎ•Î™:
            - ÎœÎµÏ„ÏÎ¬ÎµÎ¹ Ï€ÏŒÏƒÎ¿ "Î±Ï€Î¿Î¼Î¿Î½Ï‰Î¼Î­Î½Î·" ÎµÎ¯Î½Î±Î¹ ÎºÎ¬Î¸Îµ Î»ÏÏƒÎ·
            - ÎœÎµÎ³Î±Î»ÏÏ„ÎµÏÎ¿ distance = Ï€Î¹Î¿ Î¼Î¿Î½Î±Î´Î¹ÎºÎ® Î¸Î­ÏƒÎ· ÏƒÏ„Î¿ Pareto front
            - Î’Î¿Î·Î¸Î¬ÎµÎ¹ Î½Î± Î´Î¹Î±Ï„Î·ÏÎ®ÏƒÎ¿Ï…Î¼Îµ diversity

            Course Link: Lecture 4 - NSGA-II crowding distance
            """
            if len(front_indices) <= 2:
                for i in front_indices:
                    population[i].crowding_distance = float('inf')
                return

            for i in front_indices:
                population[i].crowding_distance = 0

            for obj in ['cost', 'detection']:
                sorted_idx = sorted(front_indices, key=lambda x: getattr(population[x], obj))
                min_val = getattr(population[sorted_idx[0]], obj)
                max_val = getattr(population[sorted_idx[-1]], obj)

                population[sorted_idx[0]].crowding_distance = float('inf')
                population[sorted_idx[-1]].crowding_distance = float('inf')

                if max_val - min_val > 0:
                    for i in range(1, len(sorted_idx) - 1):
                        prev = getattr(population[sorted_idx[i - 1]], obj)
                        next_val = getattr(population[sorted_idx[i + 1]], obj)
                        population[sorted_idx[i]].crowding_distance += (next_val - prev) / (max_val - min_val)


        def nsga2(cost_matrix, prob_matrix, pop_size, generations, mutation_rate,
                  crossover_rate=0.9, track_history=True):
            """
            NSGA-II Main Algorithm

            Î Î‘Î¡Î‘ÎœÎ•Î¤Î¡ÎŸÎ™ Î ÎŸÎ¥ Î•Î Î—Î¡Î•Î‘Î–ÎŸÎ¥Î Î¤Î—Î Î‘Î ÎŸÎ”ÎŸÎ£Î—:
            - pop_size: ÎœÎµÎ³Î±Î»ÏÏ„ÎµÏÎ¿Ï‚ = Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎ· ÎµÎ¾ÎµÏÎµÏÎ½Î·ÏƒÎ·, Î±Î»Î»Î¬ Ï€Î¹Î¿ Î±ÏÎ³ÏŒ
            - generations: Î ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎµÏ‚ = ÎºÎ±Î»ÏÏ„ÎµÏÎ· ÏƒÏÎ³ÎºÎ»Î¹ÏƒÎ·, Î±Î»Î»Î¬ Ï€Î¹Î¿ Î±ÏÎ³ÏŒ
            - mutation_rate: Î¥ÏˆÎ·Î»ÏŒÏ„ÎµÏÎ¿ = Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎ· ÎµÎ¾ÎµÏÎµÏÎ½Î·ÏƒÎ·, Ï‡Î±Î¼Î·Î»ÏŒÏ„ÎµÏÎ¿ = Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎ· ÎµÎºÎ¼ÎµÏ„Î¬Î»Î»ÎµÏ…ÏƒÎ·
            - crossover_rate: Î ÏŒÏƒÎ¿ ÏƒÏ…Ï‡Î½Î¬ ÎºÎ¬Î½Î¿Ï…Î¼Îµ crossover vs Î±Ï€Î»Î® Î±Î½Ï„Î¹Î³ÏÎ±Ï†Î®
            """
            n = len(cost_matrix)

            # Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Ï€Î»Î·Î¸Ï…ÏƒÎ¼Î¿Ï
            population = []
            for _ in range(pop_size):
                perm = np.random.permutation(n)
                population.append(Solution(perm, cost_matrix, prob_matrix))

            # Î“Î¹Î± tracking (Î±Î½ Î¸Î­Î»Î¿Ï…Î¼Îµ)
            history = {'generation': [], 'pareto_size': [], 'best_cost': [], 'best_detection': []}

            # Initial sorting
            fronts = non_dominated_sorting(population)
            for front in fronts:
                crowding_distance(population, front)

            # Main loop
            for gen in range(generations):
                # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± offspring
                offspring = []
                while len(offspring) < pop_size:
                    p1 = tournament_selection(population)
                    p2 = tournament_selection(population)

                    if random.random() < crossover_rate:
                        c1, c2 = pmx_crossover(p1, p2)
                    else:
                        c1, c2 = p1.permutation.copy(), p2.permutation.copy()

                    c1 = swap_mutation(c1, mutation_rate)
                    c2 = swap_mutation(c2, mutation_rate)

                    offspring.append(Solution(c1, cost_matrix, prob_matrix))
                    if len(offspring) < pop_size:
                        offspring.append(Solution(c2, cost_matrix, prob_matrix))

                # Î£Ï…Î½Î´Ï…Î±ÏƒÎ¼ÏŒÏ‚ Î³Î¿Î½Î­Ï‰Î½ + Ï€Î±Î¹Î´Î¹ÏÎ½
                combined = population + offspring
                fronts = non_dominated_sorting(combined)

                # Î•Ï€Î¹Î»Î¿Î³Î® Î½Î­Î¿Ï… Ï€Î»Î·Î¸Ï…ÏƒÎ¼Î¿Ï
                new_pop = []
                front_idx = 0
                while len(new_pop) + len(fronts[front_idx]) <= pop_size:
                    for i in fronts[front_idx]:
                        new_pop.append(combined[i])
                    front_idx += 1
                    if front_idx >= len(fronts):
                        break

                # Î‘Î½ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹, Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ crowding distance
                if len(new_pop) < pop_size and front_idx < len(fronts):
                    crowding_distance(combined, fronts[front_idx])
                    remaining = sorted(fronts[front_idx],
                                       key=lambda x: combined[x].crowding_distance, reverse=True)
                    for i in remaining[:pop_size - len(new_pop)]:
                        new_pop.append(combined[i])

                population = new_pop

                # Update ranks
                fronts = non_dominated_sorting(population)
                for front in fronts:
                    crowding_distance(population, front)

                # Track history
                if track_history:
                    pareto = [p for p in population if p.rank == 0]
                    history['generation'].append(gen)
                    history['pareto_size'].append(len(pareto))
                    history['best_cost'].append(min(p.cost for p in population))
                    history['best_detection'].append(max(p.detection for p in population))

            return population, history


        # ============================================================
        # ============================================================
        #     SECTION: Î Î‘Î¡Î‘ÎœÎ•Î¤Î¡ÎŸÎ™ Î ÎŸÎ¥ Î‘Î›Î›Î‘Î–Î•Î™Î£ Î•Î£Î¥
        # ============================================================
        # ============================================================

        """
        ÎŸÎ”Î—Î“Î™Î•Î£:
        Î†Î»Î»Î±Î¾Îµ Ï„Î¹Ï‚ Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ Ï„Î¹Î¼Î­Ï‚ ÎºÎ±Î¹ Ï€Î±ÏÎ±Ï„Î®ÏÎ·ÏƒÎµ Ï€ÏÏ‚ Î±Î»Î»Î¬Î¶Î¿Ï…Î½ Ï„Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±!

        Î Î•Î™Î¡Î‘ÎœÎ‘ A - Multiple Runs:
        - Î£ÎºÎ¿Ï€ÏŒÏ‚: ÎÎ± Î´Î¿ÏÎ¼Îµ Î±Î½ Î¿ Î±Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Ï‚ Î´Î¯Î½ÎµÎ¹ consistent Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±
        - Î“Î¹Î±Ï„Î¯: ÎŸÎ¹ evolutionary algorithms ÎµÎ¯Î½Î±Î¹ stochastic (Ï„Ï…Ï‡Î±Î¯Î¿Î¹)
        - Î¤Î¹ Ï€ÎµÏÎ¹Î¼Î­Î½Î¿Ï…Î¼Îµ: ÎœÎ¹ÎºÏÏŒ standard deviation = ÎºÎ±Î»Î® consistency

        Î Î•Î™Î¡Î‘ÎœÎ‘ B - Parameter Sensitivity:
        - Î£ÎºÎ¿Ï€ÏŒÏ‚: ÎÎ± Î´Î¿ÏÎ¼Îµ Ï€Î¿Î¹ÎµÏ‚ Ï€Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹ ÎµÏ€Î·ÏÎµÎ¬Î¶Î¿Ï…Î½ Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎ¿
        - Î“Î¹Î±Ï„Î¯: Î“Î¹Î± Î½Î± ÎºÎ¬Î½Î¿Ï…Î¼Îµ ÏƒÏ‰ÏƒÏ„ÏŒ tuning
        - Î¤Î¹ Ï€ÎµÏÎ¹Î¼Î­Î½Î¿Ï…Î¼Îµ: ÎÎ± Î²ÏÎ¿ÏÎ¼Îµ sweet spot Î³Î¹Î± ÎºÎ¬Î¸Îµ Ï€Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿

        Î Î•Î™Î¡Î‘ÎœÎ‘ C - Convergence:
        - Î£ÎºÎ¿Ï€ÏŒÏ‚: ÎÎ± Î´Î¿ÏÎ¼Îµ Ï€ÏŒÏƒÎ¿ Î³ÏÎ®Î³Î¿ÏÎ± converge Î¿ Î±Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Ï‚
        - Î“Î¹Î±Ï„Î¯: Lecture 4 ÏÏ‰Ï„Î¬ÎµÎ¹ "how quickly did it get there?"
        - Î¤Î¹ Ï€ÎµÏÎ¹Î¼Î­Î½Î¿Ï…Î¼Îµ: Î“ÏÎ®Î³Î¿ÏÎ· Î²ÎµÎ»Ï„Î¯Ï‰ÏƒÎ· ÏƒÏ„Î·Î½ Î±ÏÏ‡Î®, ÏƒÏ„Î±Î¸ÎµÏÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Î¼ÎµÏ„Î¬
        """

        # ------------------------------
        # Î Î•Î™Î¡Î‘ÎœÎ‘ A: Multiple Runs
        # ------------------------------
        # Î‘Î›Î›Î‘ÎÎ• Î‘Î¥Î¤Î‘:
        N_RUNS = 30  # Î ÏŒÏƒÎµÏ‚ Ï†Î¿ÏÎ­Ï‚ Î½Î± Ï„ÏÎ­Î¾ÎµÎ¹ (ÏƒÏ…Î½Î¹ÏƒÏ„ÏÎ¼ÎµÎ½Î¿: 30 Î³Î¹Î± report)
        POP_SIZE_A = 200  # ÎœÎ­Î³ÎµÎ¸Î¿Ï‚ Ï€Î»Î·Î¸Ï…ÏƒÎ¼Î¿Ï
        GENERATIONS_A = 200  # Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ Î³ÎµÎ½ÎµÏÎ½ (Î¬ÏÏ‡Î¹ÏƒÎµ Î¼Îµ 50, Î¼ÎµÏ„Î¬ Î´Î¿ÎºÎ¯Î¼Î±ÏƒÎµ 100)
        MUTATION_RATE_A = 0.1  # Mutation rate (Î´Î¿ÎºÎ¯Î¼Î±ÏƒÎµ: 0.05, 0.1, 0.2)

        # ------------------------------
        # Î Î•Î™Î¡Î‘ÎœÎ‘ B: Parameter Sensitivity
        # ------------------------------
        # Î‘Î›Î›Î‘ÎÎ• Î‘Î¥Î¤Î‘ Î³Î¹Î± Î½Î± Î´ÎµÎ¹Ï‚ Ï€ÏÏ‚ ÎµÏ€Î·ÏÎµÎ¬Î¶Î¿Ï…Î½:
        POP_SIZES = [50, 100, 200]  # Î”Î¿ÎºÎ¯Î¼Î±ÏƒÎµ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬ Î¼ÎµÎ³Î­Î¸Î·
        GENERATION_VALUES = [50, 100, 200]  # Î”Î¿ÎºÎ¯Î¼Î±ÏƒÎµ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ Î³ÎµÎ½Î¹Î­Ï‚
        MUTATION_RATES = [0.05, 0.1, 0.2]  # Î”Î¿ÎºÎ¯Î¼Î±ÏƒÎµ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬ rates
        N_RUNS_B = 5  # Runs Î±Î½Î¬ configuration

        # ------------------------------
        # Î Î•Î™Î¡Î‘ÎœÎ‘ C: Convergence Analysis
        # ------------------------------
        # Î‘Î›Î›Î‘ÎÎ• Î‘Î¥Î¤Î‘:
        GENERATIONS_C = 200  # Î ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎµÏ‚ Î³ÎµÎ½Î¹Î­Ï‚ Î³Î¹Î± Î½Î± Î´ÎµÎ¹Ï‚ convergence
        POP_SIZE_C = 200


        # ============================================================
        # SECTION: Î Î•Î™Î¡Î‘ÎœÎ‘Î¤Î‘ (ÎœÎ·Î½ Î±Î»Î»Î¬Î¾ÎµÎ¹Ï‚ Ï„Î¿Î½ ÎºÏÎ´Î¹ÎºÎ±, Î¼ÏŒÎ½Î¿ Ï„Î¹Ï‚ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï…Ï‚ Ï€Î¬Î½Ï‰)
        # ============================================================

        def run_experiment_A(cost_matrix, prob_matrix):
            """
            Î Î•Î™Î¡Î‘ÎœÎ‘ A: Multiple Runs

            Î£ÎšÎŸÎ ÎŸÎ£: ÎÎ± Î´Î¿ÏÎ¼Îµ Î±Î½ Î¿ Î±Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Ï‚ ÎµÎ¯Î½Î±Î¹ consistent

            Î¤Î™ ÎœÎ•Î¤Î¡Î‘ÎœÎ•:
            - Pareto front size: Î ÏŒÏƒÎµÏ‚ non-dominated Î»ÏÏƒÎµÎ¹Ï‚ Î²ÏÎ®ÎºÎµ
            - Best cost: Î— Ï†Î¸Î·Î½ÏŒÏ„ÎµÏÎ· Î»ÏÏƒÎ·
            - Best detection: Î— Î»ÏÏƒÎ· Î¼Îµ Ï…ÏˆÎ·Î»ÏŒÏ„ÎµÏÎ· Î±Î½Î¯Ï‡Î½ÎµÏ…ÏƒÎ·
            """
            print("\n" + "=" * 60)
            print("Î Î•Î™Î¡Î‘ÎœÎ‘ A: Multiple Runs")
            print("=" * 60)
            print(f"Î Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹: runs={N_RUNS}, pop={POP_SIZE_A}, gen={GENERATIONS_A}, mut={MUTATION_RATE_A}")
            print("-" * 60)

            results = {'pareto_sizes': [], 'best_costs': [], 'best_detections': [], 'times': []}

            for run in range(N_RUNS):
                # Î”Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÏŒ seed Î³Î¹Î± ÎºÎ¬Î¸Îµ run
                np.random.seed(run * 42)
                random.seed(run * 42)

                start = time.time()
                population, _ = nsga2(cost_matrix, prob_matrix,
                                      POP_SIZE_A, GENERATIONS_A, MUTATION_RATE_A,
                                      track_history=False)
                elapsed = time.time() - start

                pareto = [p for p in population if p.rank == 0]

                results['pareto_sizes'].append(len(pareto))
                results['best_costs'].append(min(p.cost for p in pareto))
                results['best_detections'].append(max(p.detection for p in pareto))
                results['times'].append(elapsed)

                print(f"  Run {run + 1}/{N_RUNS}: Pareto={len(pareto)}, "
                      f"Cost=[{min(p.cost for p in pareto):.0f}], "
                      f"Time={elapsed:.2f}s")

            # Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬
            print("\n" + "-" * 60)
            print("Î£Î¤Î‘Î¤Î™Î£Î¤Î™ÎšÎ‘:")
            print(f"  Pareto Size: {np.mean(results['pareto_sizes']):.1f} Â± {np.std(results['pareto_sizes']):.1f}")
            print(f"  Best Cost:   {np.mean(results['best_costs']):.0f} Â± {np.std(results['best_costs']):.0f}")
            print(
                f"  Best Det:    {np.mean(results['best_detections']):.2f} Â± {np.std(results['best_detections']):.2f}")
            print(f"  Avg Time:    {np.mean(results['times']):.2f}s")

            return results


        def run_experiment_B(cost_matrix, prob_matrix):
            """
            Î Î•Î™Î¡Î‘ÎœÎ‘ B: Parameter Sensitivity

            Î£ÎšÎŸÎ ÎŸÎ£: ÎÎ± Î´Î¿ÏÎ¼Îµ Ï€ÏÏ‚ ÎµÏ€Î·ÏÎµÎ¬Î¶Î¿Ï…Î½ Î¿Î¹ Ï€Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹ Ï„Î·Î½ Î±Ï€ÏŒÎ´Î¿ÏƒÎ·

            Î¤Î™ Î”ÎŸÎšÎ™ÎœÎ‘Î–ÎŸÎ¥ÎœÎ•:
            - Î”Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬ population sizes
            - Î”Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¿ÏÏ‚ Î±ÏÎ¹Î¸Î¼Î¿ÏÏ‚ Î³ÎµÎ½ÎµÏÎ½
            - Î”Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬ mutation rates
            """
            print("\n" + "=" * 60)
            print("Î Î•Î™Î¡Î‘ÎœÎ‘ B: Parameter Sensitivity")
            print("=" * 60)

            results = {}

            # B1: Population Size
            print("\n--- B1: Effect of Population Size ---")
            for pop_size in POP_SIZES:
                pareto_sizes = []
                for run in range(N_RUNS_B):
                    np.random.seed(run * 42)
                    random.seed(run * 42)
                    population, _ = nsga2(cost_matrix, prob_matrix,
                                          pop_size, 100, 0.1, track_history=False)
                    pareto = [p for p in population if p.rank == 0]
                    pareto_sizes.append(len(pareto))

                results[f'pop_{pop_size}'] = np.mean(pareto_sizes)
                print(f"  Pop={pop_size}: Pareto={np.mean(pareto_sizes):.1f} Â± {np.std(pareto_sizes):.1f}")

            # B2: Generations
            print("\n--- B2: Effect of Generations ---")
            for gen in GENERATION_VALUES:
                pareto_sizes = []
                for run in range(N_RUNS_B):
                    np.random.seed(run * 42)
                    random.seed(run * 42)
                    population, _ = nsga2(cost_matrix, prob_matrix,
                                          100, gen, 0.1, track_history=False)
                    pareto = [p for p in population if p.rank == 0]
                    pareto_sizes.append(len(pareto))

                results[f'gen_{gen}'] = np.mean(pareto_sizes)
                print(f"  Gen={gen}: Pareto={np.mean(pareto_sizes):.1f} Â± {np.std(pareto_sizes):.1f}")

            # B3: Mutation Rate
            print("\n--- B3: Effect of Mutation Rate ---")
            for mut in MUTATION_RATES:
                pareto_sizes = []
                for run in range(N_RUNS_B):
                    np.random.seed(run * 42)
                    random.seed(run * 42)
                    population, _ = nsga2(cost_matrix, prob_matrix,
                                          100, 100, mut, track_history=False)
                    pareto = [p for p in population if p.rank == 0]
                    pareto_sizes.append(len(pareto))

                results[f'mut_{mut}'] = np.mean(pareto_sizes)
                print(f"  Mut={mut}: Pareto={np.mean(pareto_sizes):.1f} Â± {np.std(pareto_sizes):.1f}")

            return results


        def run_experiment_C(cost_matrix, prob_matrix):
            """
            Î Î•Î™Î¡Î‘ÎœÎ‘ C: Convergence Analysis

            Î£ÎšÎŸÎ ÎŸÎ£: ÎÎ± Î´Î¿ÏÎ¼Îµ Ï€ÏŒÏƒÎ¿ Î³ÏÎ®Î³Î¿ÏÎ± converge Î¿ Î±Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Ï‚

            Course Link: Lecture 4 - "how quickly did it get there?"
            """
            print("\n" + "=" * 60)
            print("Î Î•Î™Î¡Î‘ÎœÎ‘ C: Convergence Analysis")
            print("=" * 60)
            print(f"Î Î±ÏÎ¬Î¼ÎµÏ„ÏÎ¿Î¹: pop={POP_SIZE_C}, gen={GENERATIONS_C}")
            print("-" * 60)

            np.random.seed(42)
            random.seed(42)

            population, history = nsga2(cost_matrix, prob_matrix,
                                        POP_SIZE_C, GENERATIONS_C, 0.1,
                                        track_history=True)

            print(f"\nÎ¤ÎµÎ»Î¹ÎºÎ¬ Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± Î¼ÎµÏ„Î¬ Î±Ï€ÏŒ {GENERATIONS_C} Î³ÎµÎ½Î¹Î­Ï‚:")
            print(f"  Pareto Front Size: {history['pareto_size'][-1]}")
            print(f"  Best Cost: {history['best_cost'][-1]:.0f}")
            print(f"  Best Detection: {history['best_detection'][-1]:.2f}")

            # Î’ÏÎµÏ‚ Ï€ÏŒÏ„Îµ ÏƒÏ„Î±Î¸ÎµÏÎ¿Ï€Î¿Î¹Î®Î¸Î·ÎºÎµ
            sizes = history['pareto_size']
            converged_gen = GENERATIONS_C
            for i in range(len(sizes) - 10):
                if abs(sizes[i] - sizes[-1]) < 5:
                    converged_gen = i
                    break
            print(f"  Î£Ï„Î±Î¸ÎµÏÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Ï€ÎµÏÎ¯Ï€Î¿Ï… ÏƒÏ„Î· Î³ÎµÎ½Î¹Î¬: {converged_gen}")

            return history, population


        # ============================================================
        # SECTION: VISUALIZATION (Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î³ÏÎ±Ï†Î·Î¼Î¬Ï„Ï‰Î½)
        # ============================================================

        def create_visualizations(results_A, results_B, history_C, population_C):
            """Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î³ÏÎ±Ï†Î·Î¼Î¬Ï„Ï‰Î½ Î³Î¹Î± Ï„Î¿ report"""

            # 1. Multiple Runs Results
            fig, axes = plt.subplots(1, 3, figsize=(15, 4))

            axes[0].hist(results_A['pareto_sizes'], bins=10, color='steelblue', edgecolor='black')
            axes[0].axvline(np.mean(results_A['pareto_sizes']), color='red', linestyle='--',
                            label=f'Mean: {np.mean(results_A["pareto_sizes"]):.1f}')
            axes[0].set_xlabel('Pareto Front Size')
            axes[0].set_ylabel('Frequency')
            axes[0].set_title('Distribution of Pareto Front Sizes')
            axes[0].legend()

            axes[1].hist(results_A['best_costs'], bins=10, color='coral', edgecolor='black')
            axes[1].set_xlabel('Best Cost')
            axes[1].set_title('Distribution of Best Costs')

            axes[2].hist(results_A['best_detections'], bins=10, color='forestgreen', edgecolor='black')
            axes[2].set_xlabel('Best Detection')
            axes[2].set_title('Distribution of Best Detections')

            plt.tight_layout()
            plt.savefig('exp_A_multiple_runs.png', dpi=300)
            plt.close()
            print("Saved: exp_A_multiple_runs.png")

            # 2. Convergence Plot
            fig, axes = plt.subplots(2, 2, figsize=(12, 10))

            axes[0, 0].plot(history_C['generation'], history_C['pareto_size'], 'b-', linewidth=2)
            axes[0, 0].set_xlabel('Generation')
            axes[0, 0].set_ylabel('Pareto Front Size')
            axes[0, 0].set_title('Pareto Front Size Evolution')
            axes[0, 0].grid(True, alpha=0.3)

            axes[0, 1].plot(history_C['generation'], history_C['best_cost'], 'r-', linewidth=2)
            axes[0, 1].set_xlabel('Generation')
            axes[0, 1].set_ylabel('Best Cost')
            axes[0, 1].set_title('Best Cost Evolution')
            axes[0, 1].grid(True, alpha=0.3)

            axes[1, 0].plot(history_C['generation'], history_C['best_detection'], 'g-', linewidth=2)
            axes[1, 0].set_xlabel('Generation')
            axes[1, 0].set_ylabel('Best Detection')
            axes[1, 0].set_title('Best Detection Evolution')
            axes[1, 0].grid(True, alpha=0.3)

            # Final Pareto Front
            pareto = [p for p in population_C if p.rank == 0]
            costs = [p.cost for p in pareto]
            dets = [p.detection for p in pareto]
            sorted_points = sorted(zip(costs, dets))
            x, y = zip(*sorted_points)

            axes[1, 1].scatter(x, y, c='red', s=30)
            axes[1, 1].plot(x, y, 'r-', alpha=0.5)
            axes[1, 1].set_xlabel('Cost (Minimize)')
            axes[1, 1].set_ylabel('Detection (Maximize)')
            axes[1, 1].set_title(f'Final Pareto Front ({len(pareto)} solutions)')
            axes[1, 1].grid(True, alpha=0.3)

            plt.tight_layout()
            plt.savefig('exp_C_convergence.png', dpi=300)
            plt.close()
            print("Saved: exp_C_convergence.png")

            # 3. Parameter Sensitivity Bar Chart
            fig, axes = plt.subplots(1, 3, figsize=(15, 4))

            pop_vals = [results_B.get(f'pop_{p}', 0) for p in POP_SIZES]
            axes[0].bar(range(len(POP_SIZES)), pop_vals, color='steelblue')
            axes[0].set_xticks(range(len(POP_SIZES)))
            axes[0].set_xticklabels(POP_SIZES)
            axes[0].set_xlabel('Population Size')
            axes[0].set_ylabel('Pareto Front Size')
            axes[0].set_title('Effect of Population Size')

            gen_vals = [results_B.get(f'gen_{g}', 0) for g in GENERATION_VALUES]
            axes[1].bar(range(len(GENERATION_VALUES)), gen_vals, color='coral')
            axes[1].set_xticks(range(len(GENERATION_VALUES)))
            axes[1].set_xticklabels(GENERATION_VALUES)
            axes[1].set_xlabel('Generations')
            axes[1].set_title('Effect of Generations')

            mut_vals = [results_B.get(f'mut_{m}', 0) for m in MUTATION_RATES]
            axes[2].bar(range(len(MUTATION_RATES)), mut_vals, color='forestgreen')
            axes[2].set_xticks(range(len(MUTATION_RATES)))
            axes[2].set_xticklabels(MUTATION_RATES)
            axes[2].set_xlabel('Mutation Rate')
            axes[2].set_title('Effect of Mutation Rate')

            plt.tight_layout()
            plt.savefig('exp_B_parameters.png', dpi=300)
            plt.close()
            print("Saved: exp_B_parameters.png")


        # ============================================================
        # MAIN - Î¤ÏÎ­Î¾Îµ Ï„Î± Ï€ÎµÎ¹ÏÎ¬Î¼Î±Ï„Î±
        # ============================================================

        if __name__ == "__main__":
            print("\n" + "=" * 70)
            print("  COMP5012 - Step 6: Experimental Design")
            print("  Dataset: assign100.txt (100 drones Ã— 100 areas)")
            print("=" * 70)

            # Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
            print("\nÎ¦ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½...")
            cost_matrix = load_cost_matrix(r"C:\Users\apzym\OneDrive\Desktop\PLYMOUTH\COMP5012\assign100.txt")
            prob_matrix = generate_probability_matrix(100, seed=42)
            print(f"  Cost matrix: {cost_matrix.shape}")
            print(f"  Probability matrix: {prob_matrix.shape}")

            # Î¤ÏÎ­Î¾Îµ Ï„Î± Ï€ÎµÎ¹ÏÎ¬Î¼Î±Ï„Î±
            results_A = run_experiment_A(cost_matrix, prob_matrix)
            results_B = run_experiment_B(cost_matrix, prob_matrix)
            history_C, population_C = run_experiment_C(cost_matrix, prob_matrix)

            # Î”Î·Î¼Î¹Î¿ÏÏÎ³Î·ÏƒÎµ Î³ÏÎ±Ï†Î®Î¼Î±Ï„Î±
            print("\n" + "=" * 60)
            print("Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î“ÏÎ±Ï†Î·Î¼Î¬Ï„Ï‰Î½...")
            print("=" * 60)
            create_visualizations(results_A, results_B, history_C, population_C)

            print("\n" + "=" * 70)
            print("  ÎŸÎ›ÎŸÎšÎ›Î—Î¡Î©Î˜Î—ÎšÎ•!")
            print("=" * 70)
            print("\nÎ‘ÏÏ‡ÎµÎ¯Î± Ï€Î¿Ï… Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎ±Î½:")
            print("  - exp_A_multiple_runs.png")
            print("  - exp_B_parameters.png")
            print("  - exp_C_convergence.png")
            print("\nğŸ’¡ Î•Î ÎŸÎœÎ•ÎÎŸ Î’Î—ÎœÎ‘: Î†Î»Î»Î±Î¾Îµ Ï„Î¹Ï‚ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï…Ï‚ ÏƒÏ„Î¿ SECTION 'Î Î‘Î¡Î‘ÎœÎ•Î¤Î¡ÎŸÎ™'")
            print("   ÎºÎ±Î¹ Î¾Î±Î½Î±Ï„ÏÎ­Î¾Îµ Î³Î¹Î± Î½Î± Î´ÎµÎ¹Ï‚ Ï€ÏÏ‚ Î±Î»Î»Î¬Î¶Î¿Ï…Î½ Ï„Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±!")